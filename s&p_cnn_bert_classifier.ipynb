{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "s&p_cnn_bert_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "167ed117",
        "CPm4AfOP64eQ"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predizione di indici di borsa tramite financial news sentiment analysis"
      ],
      "metadata": {
        "id": "VLo_2TkOYTy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Progetto per tesi\n",
        "\n",
        "Studente: Gian Luca Nediani\n",
        "\n",
        "E-mail: gianluca.nediani@studio.unibo.it"
      ],
      "metadata": {
        "id": "Ueb-qY6mYa3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduzione"
      ],
      "metadata": {
        "id": "ffBg7MqIYeBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partire da quanto mostrato nel paper [Deep Learning for Event-Driven Stock Prediction](https://www.ijcai.org/Proceedings/15/Papers/329.pdf), l'obiettivo è sviluppare una rete neurale in grado di predire l'andamento del mercato azionario tramite metodi di sentiment analysis: valutando le news di carattere finanziario di un dato giorno si vuole predire se il giorno dopo il valore di un certo indice di borsa aumenterà o diminuirà. Come nel paper, l'indice di riferimento utilizzato è _S&P500_, un indice rappresentativo delle performance delle 500 aziende più quotate nella borsa statunitense.\n",
        "\n",
        "Per comprendere il significato semantico delle news e fare valutazioni sull'andamento del mercato, gli autori del paper rappresentano le news finanziarie come degli eventi. In questo esperimento invece, si farà ricorso a un'architettura Transformer, l'attuale stato dell'arte nel _natural language processing_. Grazie all'encoder di questa architettura, sarà possibile generare degli embedding in grado di rappresentare in maniera ricca il significato semantico dei titoli di notizie finanziarie. Questi embedding saranno poi l'input per una rete neurale di classificazione.\n",
        "\n",
        "Come nel paper originale per realizzare una predizione per un dato giorno vengono utilizzate news finanziarie dell'intero mese precedente, al fine di realizzare un classificatore binario in grado di predire il rialzo/ribasso del valore dell'indice di riferimento S&P 500. Un modello efficace in tale predizione binaria, permetterebbe proficui guadagni nel mercato azionario grazie a operazioni di _day trading_.\n",
        "\n",
        "Dopo aver creato gli embedding ed averli sfruttati per costruire un dataset, quest'ultimo verrà utilizzato per addestrare e valutare una rete neurale di classificazione basata su layer convoluzionali e lineari. Il modello sarà valutato nella sezione conclusiva sia con metriche di performance che in un contesto simulativo di trading, al fine di verificarne l'effettiva efficacia in un caso d'uso pratico."
      ],
      "metadata": {
        "id": "lb969tN8YgSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installazioni e import"
      ],
      "metadata": {
        "id": "gtDhKSXqNAlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance # retrieve financial data\n",
        "!pip install transformers # library for pre-trained language models\n",
        "!pip install talib-binary # financial indicators"
      ],
      "metadata": {
        "id": "d214f344",
        "outputId": "150bc41c-a467-4f57-b815-fa8861018a1e",
        "execution": {
          "iopub.status.busy": "2022-01-09T14:49:43.692715Z",
          "iopub.execute_input": "2022-01-09T14:49:43.693020Z",
          "iopub.status.idle": "2022-01-09T14:50:02.015390Z",
          "shell.execute_reply.started": "2022-01-09T14:49:43.692940Z",
          "shell.execute_reply": "2022-01-09T14:50:02.014421Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.70)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.8.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.5)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: talib-binary in /usr/local/lib/python3.7/dist-packages (0.4.19)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from talib-binary) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np # work efficiently with n-dimensional arrays\n",
        "import torch # deep learning library\n",
        "import datetime # work with date format\n",
        "import sklearn # pre-processing functions\n",
        "import talib as ta\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup, BertTokenizer, BertModel\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "from urllib.request import urlopen\n",
        "import cloudpickle as cp\n",
        "import math"
      ],
      "metadata": {
        "id": "c7cb883c",
        "execution": {
          "iopub.status.busy": "2022-01-09T14:50:02.019077Z",
          "iopub.execute_input": "2022-01-09T14:50:02.019522Z",
          "iopub.status.idle": "2022-01-09T14:50:09.145094Z",
          "shell.execute_reply.started": "2022-01-09T14:50:02.019489Z",
          "shell.execute_reply": "2022-01-09T14:50:09.144200Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parametri dell'esperimento"
      ],
      "metadata": {
        "id": "hSsh5F-TGaRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il periodo coperto dal dataset finanziario va dal 2 febbraio 2007 al 29 novembre 2013. Tramite il seguente iperparametro è possibile modificare la data che segna l'inizio del test set."
      ],
      "metadata": {
        "id": "hPaF1qt1GEPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# date string format: yyyy-mm-dd, latest date in dataset is 2013-11-28\n",
        "SPLIT_DATE = \"2013-01-01\""
      ],
      "metadata": {
        "id": "Y6z6kPvf2DOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se questo flag è impostato a _True_, gli encoding delle notizie vengono calcolati, se è impostato a _False_ vengono invece scaricati gli embedding pre-calcolati in precedenza"
      ],
      "metadata": {
        "id": "Z8qonwkgz1Xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COMPUTE_ENCODINGS = False"
      ],
      "metadata": {
        "id": "luNrGDgORKP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Riproducibilità"
      ],
      "metadata": {
        "id": "9JJ8QCk8XpNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'intero esperimento è implementato in PyTorch. Per garantirne la riproducibilità, vengono adottate una serie di misure preliminari, come indicato nella [documentazione PyTorch sulla riproducibilità](https://pytorch.org/docs/stable/notes/randomness.html)."
      ],
      "metadata": {
        "id": "uavjYu-7XxqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "\n",
        "seed = 0\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "metadata": {
        "id": "qkIL0gyJYKcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un certo grado di variabilità nelle performance del modello sarà comunque presente in quanto l'operazione di max pooling 3d che verrà utilizzata nella rete neurale [non ha in PyTorch implementazioni deterministiche](https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html)."
      ],
      "metadata": {
        "id": "EMnmgkk_Epjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder BERT"
      ],
      "metadata": {
        "id": "167ed117"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Path dei pesi del modello transformer preaddestrato. Pesi BERT standard con testo lower cased."
      ],
      "metadata": {
        "id": "vjso5bhJzL33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = 'bert-base-uncased'"
      ],
      "metadata": {
        "id": "cLZN70p5zKNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viene utilizzata la GPU fornita da Colab, in quanto il calcolo degli embedding e l'addestramento della rete neurale tramite CPU sarebbero troppo lenti."
      ],
      "metadata": {
        "id": "5TV7FOmIZlY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))\n",
        "CUDA_LAUNCH_BLOCKING = \"1\""
      ],
      "metadata": {
        "id": "25a64665",
        "outputId": "ad366304-cc56-4c92-956a-3942bbd1086c",
        "execution": {
          "iopub.status.busy": "2022-01-09T14:50:09.165272Z",
          "iopub.execute_input": "2022-01-09T14:50:09.165552Z",
          "iopub.status.idle": "2022-01-09T14:50:09.224935Z",
          "shell.execute_reply.started": "2022-01-09T14:50:09.165515Z",
          "shell.execute_reply": "2022-01-09T14:50:09.222827Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per prima cosa viene caricato l'encoder di un modello Transformer pre-addestrato. Questo encoder è già addestrato e dunque in grado di calcolare gli embedding delle notizie finanziarie."
      ],
      "metadata": {
        "id": "wSPmm_5Mz-_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = BertModel.from_pretrained(MODEL_PATH, output_hidden_states=True).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8N4tgv2z-su",
        "outputId": "661fba33-3fdd-45a8-bfec-37208de674bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viene caricato anche il relativo tokenizer"
      ],
      "metadata": {
        "id": "Mm02FHc3zElU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH, truncation=True)"
      ],
      "metadata": {
        "id": "BsNsEFF4N6wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding del testo in embedding con attention"
      ],
      "metadata": {
        "id": "5ba43886"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Il dataset\n",
        "\n",
        "Il dataset utilizzato in questo esperimento è ottenuto a partire da due dataset di news finanziarie, entrambi utilizzati nel paper [Deep Learning for Event-Driven Stock Prediction](https://www.ijcai.org/Proceedings/15/Papers/329.pdf). Essi racchiudono rispettivamente 450341 news di natura finanziaria provenienti dalla testata giornalistica _Bloomberg_ e 109110 news di natura finanziaria provenienti dalla testata giornalistica _Reuters_. Sulle orme del paper sopracitato, sono stati estratti soltanto i titoli delle news, in quanto considerati più significativi del corpo della notizia. Inoltre, siccome il modello sviluppato può processare un numero finito di informazioni, i titoli sono stati filtrati, mantenendo solo quelli che includano il nome di uno o più degli indici di borsa che compongono l'indice _S&P500_. \n",
        "Le operazioni preliminari appena descritte portano ad avere il seguente file CSV, che per ogni giorno del periodo preso in esame (2007-2013), unisce i titoli di Bloomberg e Reuters."
      ],
      "metadata": {
        "id": "6jPRMG9TbaUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "if not os.path.exists(\"financial_titles.csv\"):\n",
        "    urlretrieve(\"https://raw.githubusercontent.com/gned0/NLP_stock_prediction/main/financial_titles_v6.csv\", \"financial_titles.csv\")\n",
        "\n",
        "df = pd.read_csv('financial_titles.csv', delimiter=',')\n",
        "df = df.drop('Unnamed: 0', 1)\n",
        "df = df.dropna(axis=0)\n",
        "df[\"ts\"] = df[\"ts\"].astype(str)\n",
        "df[\"ts\"] = df[\"ts\"].apply(lambda x: datetime.date(int(x[:4]), int(x[4:6]), int(x[6:8]))) # datetime format to compare dates\n",
        "df = df.set_index('ts')\n",
        "df = df.sort_index()\n",
        "df.reset_index(level=0, inplace=True)\n",
        "df"
      ],
      "metadata": {
        "id": "gQCFp0kMb2Cl",
        "outputId": "95e63bef-9611-4aed-a5c2-aedb9460b921",
        "execution": {
          "iopub.status.busy": "2022-01-09T14:55:24.977232Z",
          "iopub.execute_input": "2022-01-09T14:55:24.977446Z",
          "iopub.status.idle": "2022-01-09T14:55:25.903110Z",
          "shell.execute_reply.started": "2022-01-09T14:55:24.977412Z",
          "shell.execute_reply": "2022-01-09T14:55:25.902299Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-afbd5393-ebf9-45cb-b826-53e554e3e9bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ts</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>Apple posts options expenses, stands by CEO Jo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-01-02</td>\n",
              "      <td>Apple options probe spotlights ex-officials: p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-01-03</td>\n",
              "      <td>GE completes $626 mln Thailand's BAY stake dea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-01-04</td>\n",
              "      <td>US STOCKS-Indexes end up as Intel lifts techs,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-01-05</td>\n",
              "      <td>Nasdaq says no decisions made about LSE stake*...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3212</th>\n",
              "      <td>2016-08-11</td>\n",
              "      <td>Peru detects fresh oil spill from decades-old ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3213</th>\n",
              "      <td>2016-08-12</td>\n",
              "      <td>Gilead to get attorney fees in hepatitis C pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3214</th>\n",
              "      <td>2016-08-13</td>\n",
              "      <td>Wall St. ends little changed though Nasdaq hit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3215</th>\n",
              "      <td>2016-08-15</td>\n",
              "      <td>NYSE sees double-digit Asian IPOs through 2017...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3216</th>\n",
              "      <td>2016-08-16</td>\n",
              "      <td>Australia's Domino's Pizza posts record annual...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3217 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afbd5393-ebf9-45cb-b826-53e554e3e9bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-afbd5393-ebf9-45cb-b826-53e554e3e9bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-afbd5393-ebf9-45cb-b826-53e554e3e9bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              ts                                              title\n",
              "0     2007-01-01  Apple posts options expenses, stands by CEO Jo...\n",
              "1     2007-01-02  Apple options probe spotlights ex-officials: p...\n",
              "2     2007-01-03  GE completes $626 mln Thailand's BAY stake dea...\n",
              "3     2007-01-04  US STOCKS-Indexes end up as Intel lifts techs,...\n",
              "4     2007-01-05  Nasdaq says no decisions made about LSE stake*...\n",
              "...          ...                                                ...\n",
              "3212  2016-08-11  Peru detects fresh oil spill from decades-old ...\n",
              "3213  2016-08-12  Gilead to get attorney fees in hepatitis C pat...\n",
              "3214  2016-08-13  Wall St. ends little changed though Nasdaq hit...\n",
              "3215  2016-08-15  NYSE sees double-digit Asian IPOs through 2017...\n",
              "3216  2016-08-16  Australia's Domino's Pizza posts record annual...\n",
              "\n",
              "[3217 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 330
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "THRESHOLDDATE = datetime.date(2013, 12, 1)\n",
        "df = df[(df['ts'] < THRESHOLDDATE)]"
      ],
      "metadata": {
        "id": "NUjBFb9rCrdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "VcDzz7R15mew",
        "outputId": "e9e9054d-c25f-488b-98f8-349b61ab35a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-36218eff-a622-4172-8222-5cc8311a0ddd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ts</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>Apple posts options expenses, stands by CEO Jo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-01-02</td>\n",
              "      <td>Apple options probe spotlights ex-officials: p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-01-03</td>\n",
              "      <td>GE completes $626 mln Thailand's BAY stake dea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-01-04</td>\n",
              "      <td>US STOCKS-Indexes end up as Intel lifts techs,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-01-05</td>\n",
              "      <td>Nasdaq says no decisions made about LSE stake*...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2336</th>\n",
              "      <td>2013-11-25</td>\n",
              "      <td>FAA to warn airlines of engine icing risk on B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2337</th>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>ADM makes investment commitment to Aus farmers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2338</th>\n",
              "      <td>2013-11-27</td>\n",
              "      <td>Dish chairman may remain involved in bid for L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2339</th>\n",
              "      <td>2013-11-28</td>\n",
              "      <td>Taiwan stocks rise again, Apple suppliers jump...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2340</th>\n",
              "      <td>2013-11-29</td>\n",
              "      <td>Moody's raises Greek rating to 'Caa3'*Media Ad...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2341 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36218eff-a622-4172-8222-5cc8311a0ddd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-36218eff-a622-4172-8222-5cc8311a0ddd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-36218eff-a622-4172-8222-5cc8311a0ddd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              ts                                              title\n",
              "0     2007-01-01  Apple posts options expenses, stands by CEO Jo...\n",
              "1     2007-01-02  Apple options probe spotlights ex-officials: p...\n",
              "2     2007-01-03  GE completes $626 mln Thailand's BAY stake dea...\n",
              "3     2007-01-04  US STOCKS-Indexes end up as Intel lifts techs,...\n",
              "4     2007-01-05  Nasdaq says no decisions made about LSE stake*...\n",
              "...          ...                                                ...\n",
              "2336  2013-11-25  FAA to warn airlines of engine icing risk on B...\n",
              "2337  2013-11-26  ADM makes investment commitment to Aus farmers...\n",
              "2338  2013-11-27  Dish chairman may remain involved in bid for L...\n",
              "2339  2013-11-28  Taiwan stocks rise again, Apple suppliers jump...\n",
              "2340  2013-11-29  Moody's raises Greek rating to 'Caa3'*Media Ad...\n",
              "\n",
              "[2341 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding"
      ],
      "metadata": {
        "id": "goUp_9qublD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La lunghezza massima dei titoli di news concatenati per ogni giorno nel dataset è di 512 parole, il massimo supportato dall'architettura dell'encoder BERT."
      ],
      "metadata": {
        "id": "EuWYgmdNEbtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512"
      ],
      "metadata": {
        "id": "1ffa58a8",
        "execution": {
          "iopub.status.busy": "2022-01-09T14:55:25.904593Z",
          "iopub.execute_input": "2022-01-09T14:55:25.904845Z",
          "iopub.status.idle": "2022-01-09T14:55:25.908352Z",
          "shell.execute_reply.started": "2022-01-09T14:55:25.904812Z",
          "shell.execute_reply": "2022-01-09T14:55:25.907515Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viene definito un generatore di embedding che riceve un input testuale e ne restituisce l'embedding. L'input è troncato a 512 parole nel caso sia più lungo, oppure portato a tale lunghezza tramite padding. L'output dell'encoder è un tensore 512x768, per ogni parola viene restituita dunque una rappresentazione a 768 dimensioni. Il tensore 512x768 viene poi trasformato in un tensore 1x768 da un layer di pooling."
      ],
      "metadata": {
        "id": "5LhKRoKVEluP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncodingGenerator():\n",
        "  def __init__(self, encoder, tokenizer, max_len):\n",
        "    self.encoder = encoder\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    \n",
        "    tok_out = self.tokenizer.encode_plus(text, add_special_tokens=True,\n",
        "                                          max_length=self.max_len, \n",
        "                                          pad_to_max_length=True,\n",
        "                                          return_attention_mask=True, \n",
        "                                          return_tensors=\"pt\")\n",
        "\n",
        "    return tok_out['input_ids'].to(device), tok_out['attention_mask'].to(device)\n",
        "\n",
        "  def encode(self, text):\n",
        "\n",
        "    ids, att_mask = self.tokenize(text)\n",
        "    output = self.encoder(ids, att_mask).pooler_output\n",
        "    return output # pooled 1x768 output"
      ],
      "metadata": {
        "id": "a19cd182",
        "execution": {
          "iopub.status.busy": "2022-01-09T14:55:25.909836Z",
          "iopub.execute_input": "2022-01-09T14:55:25.910355Z",
          "iopub.status.idle": "2022-01-09T14:55:25.919248Z",
          "shell.execute_reply.started": "2022-01-09T14:55:25.910297Z",
          "shell.execute_reply": "2022-01-09T14:55:25.918468Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_generator = EncodingGenerator(encoder, tokenizer, MAX_LEN)"
      ],
      "metadata": {
        "id": "a309a2d4",
        "execution": {
          "iopub.status.busy": "2022-01-09T14:55:25.920579Z",
          "iopub.execute_input": "2022-01-09T14:55:25.920832Z",
          "iopub.status.idle": "2022-01-09T14:55:25.930653Z",
          "shell.execute_reply.started": "2022-01-09T14:55:25.920799Z",
          "shell.execute_reply": "2022-01-09T14:55:25.929932Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per ogni entry viene generato il rispettivo encoding"
      ],
      "metadata": {
        "id": "E4EZyVSCb3b7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if COMPUTE_ENCODINGS:  # embeddings computed from scratch\n",
        "  encodings = []\n",
        "  for _, row in df.iterrows():\n",
        "    titles = row.title.split('. ')\n",
        "    day_encodings = []\n",
        "    with torch.no_grad():\n",
        "      for t in titles:\n",
        "        day_encodings.append(embedding_generator.encode(t))\n",
        "    tensor = torch.cat(day_encodings)\n",
        "    encodings.append(torch.mean(tensor, dim=0))\n",
        "    \n",
        "\n",
        "else: # download of pre-computed embeddings\n",
        "  encodings = cp.load(urlopen(\"https://github.com/gned0/NLP_stock_prediction/blob/main/pooled_mean_encodings.pickle?raw=true\"))"
      ],
      "metadata": {
        "id": "jVdrPTqN4OYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, e in enumerate(encodings):\n",
        "  encodings[i] = e.cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "IgISBIMKmXYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series = pd.Series(encodings)"
      ],
      "metadata": {
        "id": "5dDE3jcjM2Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(series)"
      ],
      "metadata": {
        "id": "MxT40_V_0kfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd42bd7f-120d-4673-c6a4-2a2175a18aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2341"
            ]
          },
          "metadata": {},
          "execution_count": 339
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gli embedding vengono aggiunti al dataframe"
      ],
      "metadata": {
        "id": "gv64l8Gxb6vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"encoding\"] = series\n",
        "df.rename(columns={'ts':'Date'}, inplace = True) # rename index\n",
        "df"
      ],
      "metadata": {
        "id": "3b6906e9",
        "execution": {
          "iopub.status.busy": "2022-01-09T14:58:05.411425Z",
          "iopub.execute_input": "2022-01-09T14:58:05.413069Z",
          "iopub.status.idle": "2022-01-09T14:58:05.418727Z",
          "shell.execute_reply.started": "2022-01-09T14:58:05.413030Z",
          "shell.execute_reply": "2022-01-09T14:58:05.417899Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "7da555bf-5b08-4ad4-bca0-c01d23d33da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e9560697-e1ed-4a03-b0af-c6fe843f3bb4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>title</th>\n",
              "      <th>encoding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-01-01</td>\n",
              "      <td>Apple posts options expenses, stands by CEO Jo...</td>\n",
              "      <td>[-0.9005322, -0.4893921, -0.7482412, 0.7761569...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-01-02</td>\n",
              "      <td>Apple options probe spotlights ex-officials: p...</td>\n",
              "      <td>[-0.83810675, -0.44807652, -0.7801435, 0.67675...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-01-03</td>\n",
              "      <td>GE completes $626 mln Thailand's BAY stake dea...</td>\n",
              "      <td>[-0.8717985, -0.5080216, -0.8692926, 0.7485271...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-01-04</td>\n",
              "      <td>US STOCKS-Indexes end up as Intel lifts techs,...</td>\n",
              "      <td>[-0.8352278, -0.4769462, -0.81125015, 0.677047...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-01-05</td>\n",
              "      <td>Nasdaq says no decisions made about LSE stake*...</td>\n",
              "      <td>[-0.8495539, -0.46308327, -0.8066598, 0.698230...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2336</th>\n",
              "      <td>2013-11-25</td>\n",
              "      <td>FAA to warn airlines of engine icing risk on B...</td>\n",
              "      <td>[-0.8479992, -0.47481805, -0.8599102, 0.733987...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2337</th>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>ADM makes investment commitment to Aus farmers...</td>\n",
              "      <td>[-0.8550904, -0.46234897, -0.82907385, 0.71492...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2338</th>\n",
              "      <td>2013-11-27</td>\n",
              "      <td>Dish chairman may remain involved in bid for L...</td>\n",
              "      <td>[-0.84285367, -0.4860228, -0.88535964, 0.73053...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2339</th>\n",
              "      <td>2013-11-28</td>\n",
              "      <td>Taiwan stocks rise again, Apple suppliers jump...</td>\n",
              "      <td>[-0.8323906, -0.5006465, -0.9622431, 0.7601057...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2340</th>\n",
              "      <td>2013-11-29</td>\n",
              "      <td>Moody's raises Greek rating to 'Caa3'*Media Ad...</td>\n",
              "      <td>[-0.84149206, -0.48498264, -0.8789904, 0.73342...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2341 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9560697-e1ed-4a03-b0af-c6fe843f3bb4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9560697-e1ed-4a03-b0af-c6fe843f3bb4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9560697-e1ed-4a03-b0af-c6fe843f3bb4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Date  ...                                           encoding\n",
              "0     2007-01-01  ...  [-0.9005322, -0.4893921, -0.7482412, 0.7761569...\n",
              "1     2007-01-02  ...  [-0.83810675, -0.44807652, -0.7801435, 0.67675...\n",
              "2     2007-01-03  ...  [-0.8717985, -0.5080216, -0.8692926, 0.7485271...\n",
              "3     2007-01-04  ...  [-0.8352278, -0.4769462, -0.81125015, 0.677047...\n",
              "4     2007-01-05  ...  [-0.8495539, -0.46308327, -0.8066598, 0.698230...\n",
              "...          ...  ...                                                ...\n",
              "2336  2013-11-25  ...  [-0.8479992, -0.47481805, -0.8599102, 0.733987...\n",
              "2337  2013-11-26  ...  [-0.8550904, -0.46234897, -0.82907385, 0.71492...\n",
              "2338  2013-11-27  ...  [-0.84285367, -0.4860228, -0.88535964, 0.73053...\n",
              "2339  2013-11-28  ...  [-0.8323906, -0.5006465, -0.9622431, 0.7601057...\n",
              "2340  2013-11-29  ...  [-0.84149206, -0.48498264, -0.8789904, 0.73342...\n",
              "\n",
              "[2341 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 340
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggiunta dei dati finanziari al dataset"
      ],
      "metadata": {
        "id": "CPm4AfOP64eQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ora è necessario ottenere le informazioni relative all'andamento della borsa, in particolare dell'indice S&P500. Tramite il pacchetto yfinance viene creato un dataframe con informazioni sull'andamento di tale titolo (label ^GSPC) nel periodo corrispondente a quello coperto dal dataset di news."
      ],
      "metadata": {
        "id": "HDJejISI7VQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "stock = yf.download(\"^GSPC\", start=\"2007-01-01\", end=\"2013-12-01\")\n",
        "stock.reset_index(inplace=True)\n",
        "stock.dropna(inplace=True)\n",
        "#stock.rename(columns={'Date':'ts'}, inplace = True) # rename index\n",
        "stock.drop(labels=[\"Adj Close\"], axis=1, inplace=True) # drop of non-relevant columns \n",
        "stock['Date'] = stock['Date'].astype(str).apply(lambda x: x.replace('-', '')) # format date\n",
        "stock['Date'] = stock['Date'].apply(lambda x: datetime.date(int(x[:4]), int(x[4:6]), int(x[6:8]))) # datetime format to match dates\n",
        "stock_eval = stock.copy(deep=True) # save df as it is for later gain evaluation\n",
        "stock"
      ],
      "metadata": {
        "id": "McG4Khq165Uj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72131b7-6303-4a28-a5e6-c3571b4e83ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9d3b79b2-63d4-4f95-970d-dff48bd6b85d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-01-03</td>\n",
              "      <td>1418.030029</td>\n",
              "      <td>1429.420044</td>\n",
              "      <td>1407.859985</td>\n",
              "      <td>1416.599976</td>\n",
              "      <td>3429160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-01-04</td>\n",
              "      <td>1416.599976</td>\n",
              "      <td>1421.839966</td>\n",
              "      <td>1408.430054</td>\n",
              "      <td>1418.339966</td>\n",
              "      <td>3004460000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-01-05</td>\n",
              "      <td>1418.339966</td>\n",
              "      <td>1418.339966</td>\n",
              "      <td>1405.750000</td>\n",
              "      <td>1409.709961</td>\n",
              "      <td>2919400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-01-08</td>\n",
              "      <td>1409.260010</td>\n",
              "      <td>1414.979980</td>\n",
              "      <td>1403.969971</td>\n",
              "      <td>1412.839966</td>\n",
              "      <td>2763340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-01-09</td>\n",
              "      <td>1412.839966</td>\n",
              "      <td>1415.609985</td>\n",
              "      <td>1405.420044</td>\n",
              "      <td>1412.109985</td>\n",
              "      <td>3038380000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1736</th>\n",
              "      <td>2013-11-22</td>\n",
              "      <td>1797.209961</td>\n",
              "      <td>1804.839966</td>\n",
              "      <td>1794.699951</td>\n",
              "      <td>1804.760010</td>\n",
              "      <td>3055140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1737</th>\n",
              "      <td>2013-11-25</td>\n",
              "      <td>1806.329956</td>\n",
              "      <td>1808.099976</td>\n",
              "      <td>1800.579956</td>\n",
              "      <td>1802.479980</td>\n",
              "      <td>2998540000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1738</th>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>1802.869995</td>\n",
              "      <td>1808.420044</td>\n",
              "      <td>1800.770020</td>\n",
              "      <td>1802.750000</td>\n",
              "      <td>3427120000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1739</th>\n",
              "      <td>2013-11-27</td>\n",
              "      <td>1803.479980</td>\n",
              "      <td>1808.270020</td>\n",
              "      <td>1802.770020</td>\n",
              "      <td>1807.229980</td>\n",
              "      <td>2613590000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1740</th>\n",
              "      <td>2013-11-29</td>\n",
              "      <td>1808.689941</td>\n",
              "      <td>1813.550049</td>\n",
              "      <td>1803.979980</td>\n",
              "      <td>1805.810059</td>\n",
              "      <td>1598300000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1741 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d3b79b2-63d4-4f95-970d-dff48bd6b85d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d3b79b2-63d4-4f95-970d-dff48bd6b85d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d3b79b2-63d4-4f95-970d-dff48bd6b85d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Date         Open  ...        Close      Volume\n",
              "0     2007-01-03  1418.030029  ...  1416.599976  3429160000\n",
              "1     2007-01-04  1416.599976  ...  1418.339966  3004460000\n",
              "2     2007-01-05  1418.339966  ...  1409.709961  2919400000\n",
              "3     2007-01-08  1409.260010  ...  1412.839966  2763340000\n",
              "4     2007-01-09  1412.839966  ...  1412.109985  3038380000\n",
              "...          ...          ...  ...          ...         ...\n",
              "1736  2013-11-22  1797.209961  ...  1804.760010  3055140000\n",
              "1737  2013-11-25  1806.329956  ...  1802.479980  2998540000\n",
              "1738  2013-11-26  1802.869995  ...  1802.750000  3427120000\n",
              "1739  2013-11-27  1803.479980  ...  1807.229980  2613590000\n",
              "1740  2013-11-29  1808.689941  ...  1805.810059  1598300000\n",
              "\n",
              "[1741 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viene aggiunta la feature delta, la differenza fra il prezzo di chiusura e quello di chiusura."
      ],
      "metadata": {
        "id": "WVaEHfCC7dyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stock[\"Delta\"] = stock[\"Close\"] - stock[\"Open\"]"
      ],
      "metadata": {
        "id": "fQifMHii8qkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per ottenere le etichette da usare per la classificazione delle giornate nel mercato azionario, viene creato un valore binario: 0 se in un dato giorno il valore dell'indice chiude in calo rispetto all'apertura e 1 se al contrario chiude in rialzo."
      ],
      "metadata": {
        "id": "87SWXUSL8yEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binarize(x):\n",
        "  if x > 0:\n",
        "    return 1\n",
        "  return 0"
      ],
      "metadata": {
        "id": "1LkwHHGE65ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = stock['Close'] - stock['Open']\n",
        "targets = targets.apply(binarize)\n",
        "targets"
      ],
      "metadata": {
        "id": "xL8UI4fS8z3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df0b34e6-230f-463f-9281-0097800941d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       1\n",
              "2       0\n",
              "3       1\n",
              "4       0\n",
              "       ..\n",
              "1736    1\n",
              "1737    0\n",
              "1738    0\n",
              "1739    1\n",
              "1740    0\n",
              "Length: 1741, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizzazione dei dati finanziari"
      ],
      "metadata": {
        "id": "CQW5uS04C66o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#stock.iloc[:, 1:] = (stock.iloc[:, 1:] - stock.iloc[:, 1:].min())/(stock.iloc[:, 1:].max() - stock.iloc[:, 1:].min())\n",
        "#stock"
      ],
      "metadata": {
        "id": "6jnuIyG-RXWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock.iloc[:, 1:] = (stock.iloc[:, 1:]-stock.iloc[:, 1:].mean())/(stock.iloc[:, 1:].std(ddof=0)) # standard scaling\n",
        "stock"
      ],
      "metadata": {
        "id": "qIkmVFtMCInn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9347cb6-2efd-49bf-98b7-ad5a9fa567b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-691103c0-4126-4e49-8931-0db35d88b2f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-01-03</td>\n",
              "      <td>0.560828</td>\n",
              "      <td>0.575394</td>\n",
              "      <td>0.554056</td>\n",
              "      <td>0.552794</td>\n",
              "      <td>-0.614998</td>\n",
              "      <td>-0.108611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-01-04</td>\n",
              "      <td>0.554569</td>\n",
              "      <td>0.541987</td>\n",
              "      <td>0.556531</td>\n",
              "      <td>0.560402</td>\n",
              "      <td>-0.941167</td>\n",
              "      <td>0.092818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-01-05</td>\n",
              "      <td>0.562184</td>\n",
              "      <td>0.526561</td>\n",
              "      <td>0.544897</td>\n",
              "      <td>0.522670</td>\n",
              "      <td>-1.006493</td>\n",
              "      <td>-0.566108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-01-08</td>\n",
              "      <td>0.522445</td>\n",
              "      <td>0.511752</td>\n",
              "      <td>0.537170</td>\n",
              "      <td>0.536355</td>\n",
              "      <td>-1.126347</td>\n",
              "      <td>0.209733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-01-09</td>\n",
              "      <td>0.538113</td>\n",
              "      <td>0.514529</td>\n",
              "      <td>0.543465</td>\n",
              "      <td>0.533163</td>\n",
              "      <td>-0.915117</td>\n",
              "      <td>-0.064128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1736</th>\n",
              "      <td>2013-11-22</td>\n",
              "      <td>2.220346</td>\n",
              "      <td>2.229987</td>\n",
              "      <td>2.233271</td>\n",
              "      <td>2.249919</td>\n",
              "      <td>-0.902245</td>\n",
              "      <td>0.461999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1737</th>\n",
              "      <td>2013-11-25</td>\n",
              "      <td>2.260260</td>\n",
              "      <td>2.244355</td>\n",
              "      <td>2.258795</td>\n",
              "      <td>2.239950</td>\n",
              "      <td>-0.945714</td>\n",
              "      <td>-0.262377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1738</th>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>2.245117</td>\n",
              "      <td>2.245766</td>\n",
              "      <td>2.259620</td>\n",
              "      <td>2.241130</td>\n",
              "      <td>-0.616565</td>\n",
              "      <td>-0.025368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1739</th>\n",
              "      <td>2013-11-27</td>\n",
              "      <td>2.247787</td>\n",
              "      <td>2.245105</td>\n",
              "      <td>2.268302</td>\n",
              "      <td>2.260718</td>\n",
              "      <td>-1.241355</td>\n",
              "      <td>0.220538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1740</th>\n",
              "      <td>2013-11-29</td>\n",
              "      <td>2.270589</td>\n",
              "      <td>2.268375</td>\n",
              "      <td>2.273554</td>\n",
              "      <td>2.254510</td>\n",
              "      <td>-2.021097</td>\n",
              "      <td>-0.200736</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1741 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-691103c0-4126-4e49-8931-0db35d88b2f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-691103c0-4126-4e49-8931-0db35d88b2f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-691103c0-4126-4e49-8931-0db35d88b2f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Date      Open      High       Low     Close    Volume     Delta\n",
              "0     2007-01-03  0.560828  0.575394  0.554056  0.552794 -0.614998 -0.108611\n",
              "1     2007-01-04  0.554569  0.541987  0.556531  0.560402 -0.941167  0.092818\n",
              "2     2007-01-05  0.562184  0.526561  0.544897  0.522670 -1.006493 -0.566108\n",
              "3     2007-01-08  0.522445  0.511752  0.537170  0.536355 -1.126347  0.209733\n",
              "4     2007-01-09  0.538113  0.514529  0.543465  0.533163 -0.915117 -0.064128\n",
              "...          ...       ...       ...       ...       ...       ...       ...\n",
              "1736  2013-11-22  2.220346  2.229987  2.233271  2.249919 -0.902245  0.461999\n",
              "1737  2013-11-25  2.260260  2.244355  2.258795  2.239950 -0.945714 -0.262377\n",
              "1738  2013-11-26  2.245117  2.245766  2.259620  2.241130 -0.616565 -0.025368\n",
              "1739  2013-11-27  2.247787  2.245105  2.268302  2.260718 -1.241355  0.220538\n",
              "1740  2013-11-29  2.270589  2.268375  2.273554  2.254510 -2.021097 -0.200736\n",
              "\n",
              "[1741 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viene ora effettuato il merge fra il DataFrame che contiene gli embedding e quello che contiene i dati finanziari e le etichette target. Per riassumere, gli input X forniti al classificatore sono gli embedding delle news finanziarie e i dati finanziari dei 30 giorni precedenti il giorno g della predizione, mentre l'etichetta Y è un valore binario pari a 1 se nel giorno g il valore dell'indice chiude in rialzo rispetto all'apertura, e pari a 0 viceversa. Nel caso di un rialzo si potra sfruttare una corretta predizione per acquistare il titolo all'apertura della giornata di trading per poi rivenderlo in chiusura e ottenere un profitto. In caso di ribasso si potra ottenere un profitto vendendo allo scoperto il titolo e ricomprandolo a fine giornata. Le performance effettive ottenute in un contesto di day trading dal modello verranno analizzate nella sezione conclusiva"
      ],
      "metadata": {
        "id": "s1eDEq087un_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.merge(stock, on='Date')\n",
        "df = df.set_index('Date') # dataset sorting\n",
        "df = df.sort_index() # dataset sorting\n",
        "df.reset_index(level=0, inplace=True) # dataset sorting\n",
        "df"
      ],
      "metadata": {
        "id": "AVFZO_M57vNi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242cf675-8462-4ad7-d6e4-8c57541922aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ecbb3ff0-68f9-4cbf-b6a9-e202925b83f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>title</th>\n",
              "      <th>encoding</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-01-03</td>\n",
              "      <td>GE completes $626 mln Thailand's BAY stake dea...</td>\n",
              "      <td>[-0.8717985, -0.5080216, -0.8692926, 0.7485271...</td>\n",
              "      <td>0.560828</td>\n",
              "      <td>0.575394</td>\n",
              "      <td>0.554056</td>\n",
              "      <td>0.552794</td>\n",
              "      <td>-0.614998</td>\n",
              "      <td>-0.108611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-01-04</td>\n",
              "      <td>US STOCKS-Indexes end up as Intel lifts techs,...</td>\n",
              "      <td>[-0.8352278, -0.4769462, -0.81125015, 0.677047...</td>\n",
              "      <td>0.554569</td>\n",
              "      <td>0.541987</td>\n",
              "      <td>0.556531</td>\n",
              "      <td>0.560402</td>\n",
              "      <td>-0.941167</td>\n",
              "      <td>0.092818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-01-05</td>\n",
              "      <td>Nasdaq says no decisions made about LSE stake*...</td>\n",
              "      <td>[-0.8495539, -0.46308327, -0.8066598, 0.698230...</td>\n",
              "      <td>0.562184</td>\n",
              "      <td>0.526561</td>\n",
              "      <td>0.544897</td>\n",
              "      <td>0.522670</td>\n",
              "      <td>-1.006493</td>\n",
              "      <td>-0.566108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-01-08</td>\n",
              "      <td>Escala Group to be delisted from Nasdaq Jan 10...</td>\n",
              "      <td>[-0.8316893, -0.40585136, -0.76412916, 0.63134...</td>\n",
              "      <td>0.522445</td>\n",
              "      <td>0.511752</td>\n",
              "      <td>0.537170</td>\n",
              "      <td>0.536355</td>\n",
              "      <td>-1.126347</td>\n",
              "      <td>0.209733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-01-09</td>\n",
              "      <td>Chevron 4th-qtr liquid, natural gas production...</td>\n",
              "      <td>[-0.86060226, -0.45243385, -0.6987639, 0.68889...</td>\n",
              "      <td>0.538113</td>\n",
              "      <td>0.514529</td>\n",
              "      <td>0.543465</td>\n",
              "      <td>0.533163</td>\n",
              "      <td>-0.915117</td>\n",
              "      <td>-0.064128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1737</th>\n",
              "      <td>2013-11-22</td>\n",
              "      <td>Microsoft sells over a million Xbox Ones in un...</td>\n",
              "      <td>[-0.85503674, -0.47476488, -0.82900304, 0.7227...</td>\n",
              "      <td>2.220346</td>\n",
              "      <td>2.229987</td>\n",
              "      <td>2.233271</td>\n",
              "      <td>2.249919</td>\n",
              "      <td>-0.902245</td>\n",
              "      <td>0.461999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1738</th>\n",
              "      <td>2013-11-25</td>\n",
              "      <td>FAA to warn airlines of engine icing risk on B...</td>\n",
              "      <td>[-0.8479992, -0.47481805, -0.8599102, 0.733987...</td>\n",
              "      <td>2.260260</td>\n",
              "      <td>2.244355</td>\n",
              "      <td>2.258795</td>\n",
              "      <td>2.239950</td>\n",
              "      <td>-0.945714</td>\n",
              "      <td>-0.262377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1739</th>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>ADM makes investment commitment to Aus farmers...</td>\n",
              "      <td>[-0.8550904, -0.46234897, -0.82907385, 0.71492...</td>\n",
              "      <td>2.245117</td>\n",
              "      <td>2.245766</td>\n",
              "      <td>2.259620</td>\n",
              "      <td>2.241130</td>\n",
              "      <td>-0.616565</td>\n",
              "      <td>-0.025368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1740</th>\n",
              "      <td>2013-11-27</td>\n",
              "      <td>Dish chairman may remain involved in bid for L...</td>\n",
              "      <td>[-0.84285367, -0.4860228, -0.88535964, 0.73053...</td>\n",
              "      <td>2.247787</td>\n",
              "      <td>2.245105</td>\n",
              "      <td>2.268302</td>\n",
              "      <td>2.260718</td>\n",
              "      <td>-1.241355</td>\n",
              "      <td>0.220538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1741</th>\n",
              "      <td>2013-11-29</td>\n",
              "      <td>Moody's raises Greek rating to 'Caa3'*Media Ad...</td>\n",
              "      <td>[-0.84149206, -0.48498264, -0.8789904, 0.73342...</td>\n",
              "      <td>2.270589</td>\n",
              "      <td>2.268375</td>\n",
              "      <td>2.273554</td>\n",
              "      <td>2.254510</td>\n",
              "      <td>-2.021097</td>\n",
              "      <td>-0.200736</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1742 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecbb3ff0-68f9-4cbf-b6a9-e202925b83f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecbb3ff0-68f9-4cbf-b6a9-e202925b83f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecbb3ff0-68f9-4cbf-b6a9-e202925b83f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Date  ...     Delta\n",
              "0     2007-01-03  ... -0.108611\n",
              "1     2007-01-04  ...  0.092818\n",
              "2     2007-01-05  ... -0.566108\n",
              "3     2007-01-08  ...  0.209733\n",
              "4     2007-01-09  ... -0.064128\n",
              "...          ...  ...       ...\n",
              "1737  2013-11-22  ...  0.461999\n",
              "1738  2013-11-25  ... -0.262377\n",
              "1739  2013-11-26  ... -0.025368\n",
              "1740  2013-11-27  ...  0.220538\n",
              "1741  2013-11-29  ... -0.200736\n",
              "\n",
              "[1742 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 347
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df['Open'] = df.shift(periods=1)['Open']"
      ],
      "metadata": {
        "id": "TZ6cpJVqMDsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Raggruppamento delle informazioni finanziarie di ciascuna entry in una singola colonna"
      ],
      "metadata": {
        "id": "hZtj5Bb-9Os3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"financial information\"] = df[['Open', 'High', 'Low', 'Close', 'Volume', 'Delta']].values.tolist()\n",
        "df.drop(labels=['High', 'Low', 'Close', 'Volume', 'Delta'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "bRMA-PmD9OUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggiunta etichette"
      ],
      "metadata": {
        "id": "IBwnhkmD-Gix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"target\"] = targets"
      ],
      "metadata": {
        "id": "H0OBdfI1-GW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "eU5W70SN02t7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a0b02b-62b1-4ce1-9fb8-ea7c6015aa87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-24184a03-49ed-480d-a8d3-70b2122505fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>title</th>\n",
              "      <th>encoding</th>\n",
              "      <th>Open</th>\n",
              "      <th>financial information</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-01-03</td>\n",
              "      <td>GE completes $626 mln Thailand's BAY stake dea...</td>\n",
              "      <td>[-0.8717985, -0.5080216, -0.8692926, 0.7485271...</td>\n",
              "      <td>0.560828</td>\n",
              "      <td>[0.5608277485864144, 0.5753942887782401, 0.554...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-01-04</td>\n",
              "      <td>US STOCKS-Indexes end up as Intel lifts techs,...</td>\n",
              "      <td>[-0.8352278, -0.4769462, -0.81125015, 0.677047...</td>\n",
              "      <td>0.554569</td>\n",
              "      <td>[0.5545689796245776, 0.5419865125181605, 0.556...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-01-05</td>\n",
              "      <td>Nasdaq says no decisions made about LSE stake*...</td>\n",
              "      <td>[-0.8495539, -0.46308327, -0.8066598, 0.698230...</td>\n",
              "      <td>0.562184</td>\n",
              "      <td>[0.5621842158842466, 0.5265609172957791, 0.544...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-01-08</td>\n",
              "      <td>Escala Group to be delisted from Nasdaq Jan 10...</td>\n",
              "      <td>[-0.8316893, -0.40585136, -0.76412916, 0.63134...</td>\n",
              "      <td>0.522445</td>\n",
              "      <td>[0.5224449063077798, 0.5117524104425408, 0.537...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-01-09</td>\n",
              "      <td>Chevron 4th-qtr liquid, natural gas production...</td>\n",
              "      <td>[-0.86060226, -0.45243385, -0.6987639, 0.68889...</td>\n",
              "      <td>0.538113</td>\n",
              "      <td>[0.5381129316892385, 0.5145290391026521, 0.543...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1737</th>\n",
              "      <td>2013-11-22</td>\n",
              "      <td>Microsoft sells over a million Xbox Ones in un...</td>\n",
              "      <td>[-0.85503674, -0.47476488, -0.82900304, 0.7227...</td>\n",
              "      <td>2.220346</td>\n",
              "      <td>[2.2203455477800897, 2.2299873611387584, 2.233...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1738</th>\n",
              "      <td>2013-11-25</td>\n",
              "      <td>FAA to warn airlines of engine icing risk on B...</td>\n",
              "      <td>[-0.8479992, -0.47481805, -0.8599102, 0.733987...</td>\n",
              "      <td>2.260260</td>\n",
              "      <td>[2.2602600922024365, 2.244355244300342, 2.2587...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1739</th>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>ADM makes investment commitment to Aus farmers...</td>\n",
              "      <td>[-0.8550904, -0.46234897, -0.82907385, 0.71492...</td>\n",
              "      <td>2.245117</td>\n",
              "      <td>[2.2451172371060384, 2.245765885716116, 2.2596...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1740</th>\n",
              "      <td>2013-11-27</td>\n",
              "      <td>Dish chairman may remain involved in bid for L...</td>\n",
              "      <td>[-0.84285367, -0.4860228, -0.88535964, 0.73053...</td>\n",
              "      <td>2.247787</td>\n",
              "      <td>[2.2477868972428117, 2.245104681177601, 2.2683...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1741</th>\n",
              "      <td>2013-11-29</td>\n",
              "      <td>Moody's raises Greek rating to 'Caa3'*Media Ad...</td>\n",
              "      <td>[-0.84149206, -0.48498264, -0.8789904, 0.73342...</td>\n",
              "      <td>2.270589</td>\n",
              "      <td>[2.2705887973103485, 2.268375422519289, 2.2735...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1742 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24184a03-49ed-480d-a8d3-70b2122505fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24184a03-49ed-480d-a8d3-70b2122505fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24184a03-49ed-480d-a8d3-70b2122505fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Date  ... target\n",
              "0     2007-01-03  ...    0.0\n",
              "1     2007-01-04  ...    1.0\n",
              "2     2007-01-05  ...    0.0\n",
              "3     2007-01-08  ...    1.0\n",
              "4     2007-01-09  ...    0.0\n",
              "...          ...  ...    ...\n",
              "1737  2013-11-22  ...    0.0\n",
              "1738  2013-11-25  ...    0.0\n",
              "1739  2013-11-26  ...    1.0\n",
              "1740  2013-11-27  ...    0.0\n",
              "1741  2013-11-29  ...    NaN\n",
              "\n",
              "[1742 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 351
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creazione del dataset per rete neurale di classificazione"
      ],
      "metadata": {
        "id": "f3713b5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partire dal dataframe ottenuto in precedenza, è necessario ottenere il dataset finale da utilizzare per l'addestramento e la valutazione della rete neurale di classificazione. Come spiegato in precedenza, il classificatore farà uso delle informazioni relative all'intero mese precedente alla giornata da predire. Ogni entry di tale dataset avrà le seguenti feature:\n",
        "\n",
        "*   **Data del giorno usata come indice**\n",
        "*   **Dati *testuali* a lungo termine** (embedding dei 30 giorni precedenti, matrice 30x768)\n",
        "* **Dati *finanziari* a lungo termine** (informazioni su valori di apertura, chiusura, picco, minimo e delta nei 30 giorni precedenti, matrice 30x4)\n",
        "* **Token del giorno precedente** per calcolare in fase di training gli embedding a breve termine e ottenere maggiori performance.\n",
        "\n",
        "Sarà fondamentale fare sì che il classificatore non possa accedere a informazioni future rispetto al momento in cui dovrà predire l'andamento del mercato. Il valore di apertura del giorno stesso può essere utilizzato in quanto è proprio all'apertura della giornata di trading che il modello effettua la predizione.\n",
        "\n",
        "In un caso d'uso reale, il modello utilizza per predire un rialzo/ribasso nel valore dell'indice di riferimento S&P 500 nel giorno _g_, tutte le informazioni che fanno riferimento ai giorni da _g-1_ a _g-30_. All'apertura della giornata azionaria la predizione binaria inidicherà se per l'indice è previsto un aumento o una diminuzione nel valore(differenza fra prezzo di chiusura e prezzo di apertura); in questo modo è possibile acquistare o vendere allo scoperto il titolo per ottenere un profitto alla chisura dei mercati.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bVP7pmWScYe-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prima di costruire il dataset con gli embedding e i dati finanziari, ne viene costruito uno identico con le date relative a tali informazioni. Questo viene fatto per verificare la correttezza temporale del dataset, ovvero che al momento di ogni predizione il modello non possa disporre di informazioni successive."
      ],
      "metadata": {
        "id": "PQ2Qx1v_9XJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_dates(dataframe, lookback):\n",
        "    lookback = lookback + 1\n",
        "    data_raw = dataframe.to_numpy()\n",
        "    data = []\n",
        "    # create all possible sequences of length seq_len\n",
        "    for index in range(len(data_raw) - lookback): \n",
        "        data.append(data_raw[index: index + lookback])\n",
        "    \n",
        "    data = np.array(data)\n",
        "    x = data[:, :-1, 0] # dates of input days   \n",
        "    y = data[:, -1, 0] # date\n",
        "    \n",
        "    return [x, y]"
      ],
      "metadata": {
        "id": "T2HPFacHdvuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viene ora costruito il dataset vero e proprio su cui si eseguiranno addestramento e valutazione della rete neurale di classificazione."
      ],
      "metadata": {
        "id": "t7UmeC3qIhlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(df):\n",
        "\n",
        "  final_df = pd.DataFrame({'Date': [], '30-day encodings': [], '30-day financial data': [], 'Open value': [], 'Target': []})\n",
        "  for _, row in df.iterrows():\n",
        "    prior_day = df[df[\"Date\"] == row.Date - datetime.timedelta(1)]\n",
        "    index = df.index[df[\"Date\"] == row.Date].tolist()[0]\n",
        "    if(len(prior_day) and index >= 30):\n",
        "      titles = df.iloc[index-30:index][\"encoding\"].values.tolist()\n",
        "      financial_data = df.iloc[index-30:index][\"financial information\"].values.tolist()\n",
        "      open_value = row.Open\n",
        "\n",
        "\n",
        "      entry = {'Date': row.Date, '30-day encodings': np.array(titles), '30-day financial data': np.array(financial_data), 'Open value': open_value, 'Target': row.target}\n",
        "      final_df = final_df.append(entry, ignore_index=True)\n",
        "  return final_df"
      ],
      "metadata": {
        "id": "FoRsDTwk9f-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = build_dataset(df)\n",
        "final_df"
      ],
      "metadata": {
        "id": "sZQ_2QOc9heH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "2fdf2972-75aa-447e-ba6c-f9737a5ee52e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d9fdad2d-06b8-45bb-9303-008c877f5c33\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>30-day encodings</th>\n",
              "      <th>30-day financial data</th>\n",
              "      <th>Open value</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-02-15</td>\n",
              "      <td>[[-0.8717985, -0.5080216, -0.8692926, 0.748527...</td>\n",
              "      <td>[[0.5608277485864144, 0.5753942887782401, 0.55...</td>\n",
              "      <td>0.723287</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-02-16</td>\n",
              "      <td>[[-0.8352278, -0.4769462, -0.81125015, 0.67704...</td>\n",
              "      <td>[[0.5545689796245776, 0.5419865125181605, 0.55...</td>\n",
              "      <td>0.730377</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-02-21</td>\n",
              "      <td>[[-0.8316893, -0.40585136, -0.76412916, 0.6313...</td>\n",
              "      <td>[[0.5224449063077798, 0.5117524104425408, 0.53...</td>\n",
              "      <td>0.742763</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-02-22</td>\n",
              "      <td>[[-0.86060226, -0.45243385, -0.6987639, 0.6888...</td>\n",
              "      <td>[[0.5381129316892385, 0.5145290391026521, 0.54...</td>\n",
              "      <td>0.732653</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-02-23</td>\n",
              "      <td>[[-0.86288255, -0.45067856, -0.67497903, 0.686...</td>\n",
              "      <td>[[0.5199937554757775, 0.5162038395325933, 0.54...</td>\n",
              "      <td>0.727970</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>2013-11-20</td>\n",
              "      <td>[[-0.840774, -0.45131668, -0.746046, 0.6825028...</td>\n",
              "      <td>[[1.606659226941794, 1.6025182421415707, 1.589...</td>\n",
              "      <td>2.186996</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1338</th>\n",
              "      <td>2013-11-21</td>\n",
              "      <td>[[-0.8501678, -0.46904427, -0.84191597, 0.7253...</td>\n",
              "      <td>[[1.6236842538736638, 1.7351346752863315, 1.65...</td>\n",
              "      <td>2.160430</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1339</th>\n",
              "      <td>2013-11-22</td>\n",
              "      <td>[[-0.82561904, -0.48238593, -0.88654524, 0.710...</td>\n",
              "      <td>[[1.7559010821003282, 1.7830857233813515, 1.77...</td>\n",
              "      <td>2.220346</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1340</th>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>[[-0.85612255, -0.47760183, -0.8575107, 0.7347...</td>\n",
              "      <td>[[1.8350303000666597, 1.8189171989465658, 1.80...</td>\n",
              "      <td>2.245117</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1341</th>\n",
              "      <td>2013-11-27</td>\n",
              "      <td>[[-0.8633491, -0.48155215, -0.8383037, 0.74043...</td>\n",
              "      <td>[[1.797041201938676, 1.8638279973693732, 1.824...</td>\n",
              "      <td>2.247787</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1342 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9fdad2d-06b8-45bb-9303-008c877f5c33')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d9fdad2d-06b8-45bb-9303-008c877f5c33 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d9fdad2d-06b8-45bb-9303-008c877f5c33');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Date  ... Target\n",
              "0     2007-02-15  ...    1.0\n",
              "1     2007-02-16  ...    0.0\n",
              "2     2007-02-21  ...    0.0\n",
              "3     2007-02-22  ...    0.0\n",
              "4     2007-02-23  ...    0.0\n",
              "...          ...  ...    ...\n",
              "1337  2013-11-20  ...    1.0\n",
              "1338  2013-11-21  ...    1.0\n",
              "1339  2013-11-22  ...    0.0\n",
              "1340  2013-11-26  ...    1.0\n",
              "1341  2013-11-27  ...    0.0\n",
              "\n",
              "[1342 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 354
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "90283ecd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Suddivisione del dataset"
      ],
      "metadata": {
        "id": "OvyRxKuzEjou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il dataset è diviso temporalmente a seconda della data scelta a inizio notebook"
      ],
      "metadata": {
        "id": "KW4VAHKeXkI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(dataframe, split_date):\n",
        "    is_train = dataframe['Date']<datetime.date(int(split_date[:4]), \n",
        "                                               int(split_date[5:7]), \n",
        "                                               int(split_date[8:10]))\n",
        "    df_train = dataframe[is_train]\n",
        "    df_test = dataframe[~is_train]\n",
        "\n",
        "    return df_train, df_test  \n",
        "    \n",
        "df_train, df_test = split_dataset(final_df, SPLIT_DATE)"
      ],
      "metadata": {
        "id": "lX1LJmyizUD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creazione Dataset e DataLoader"
      ],
      "metadata": {
        "id": "RgKYRe2zNZ8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vengono definite le strutture del Dataset e del relativo DataLoader per darlo in pasto alla rete neurale. I dati in input alla rete neurale sono per ogni istanza:\n",
        "\n",
        "\n",
        "*   **Data long**, concatenazione dei dati testuali e finanziari a lungo termine\n",
        "*   **Data mid**, concatenazione dei dati testuali e finanziari a medio termine\n",
        "*   **Data short**, concatenazione dei dati testuali e finanziari a breve termine, compreso il valore di apertura del giorno stesso\n",
        "\n"
      ],
      "metadata": {
        "id": "TAQp9RP-V5DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FinancialDataset(Dataset):\n",
        "  def __init__(self, data):\n",
        "    self.dates = data[..., 0]\n",
        "    self.encodings = data[..., 1]\n",
        "    self.financial_data = data[..., 2]\n",
        "    self.open_values = data[..., 3]\n",
        "    self.targets = data[..., 4]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dates)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    date = str(self.dates[item])\n",
        "    encodings = self.encodings[item]\n",
        "    financial_data = self.financial_data[item] \n",
        "    open_value = self.open_values[item]\n",
        "    target = self.targets[item]\n",
        "    data_long = np.concatenate([encodings, financial_data], axis=1)\n",
        "    data_mid =  np.concatenate([encodings[-7:, :], financial_data[-7:, :]], axis=1)\n",
        "    data_short =  np.concatenate([encodings[-1, :], financial_data[-1, :]], axis=0)    \n",
        "    return {\n",
        "      'date': date,\n",
        "      'data_long': torch.tensor(data_long, dtype=torch.float),\n",
        "      'data_mid': torch.tensor(data_mid, dtype=torch.float),\n",
        "      'data_short': torch.tensor(data_short, dtype=torch.float),\n",
        "      'open_value': torch.tensor(open_value, dtype=torch.float),\n",
        "      'targets': torch.tensor(target, dtype=torch.float)\n",
        "    }"
      ],
      "metadata": {
        "id": "ab75647c",
        "execution": {
          "iopub.status.busy": "2022-01-09T15:12:41.500030Z",
          "iopub.execute_input": "2022-01-09T15:12:41.500745Z",
          "iopub.status.idle": "2022-01-09T15:12:41.510468Z",
          "shell.execute_reply.started": "2022-01-09T15:12:41.500704Z",
          "shell.execute_reply": "2022-01-09T15:12:41.509656Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(data, batch_size):\n",
        "  ds = FinancialDataset(\n",
        "    data=data,\n",
        "  )\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        "  )"
      ],
      "metadata": {
        "id": "4dd1cf35",
        "execution": {
          "iopub.status.busy": "2022-01-09T15:12:41.513388Z",
          "iopub.execute_input": "2022-01-09T15:12:41.513630Z",
          "iopub.status.idle": "2022-01-09T15:12:41.519832Z",
          "shell.execute_reply.started": "2022-01-09T15:12:41.513594Z",
          "shell.execute_reply": "2022-01-09T15:12:41.518815Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "DWcVT04D60sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_loader = create_data_loader(df_train.to_numpy(), BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test.to_numpy(), BATCH_SIZE)"
      ],
      "metadata": {
        "id": "NqTPW4k_cdry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rete neurale convoluzionale per classificazione"
      ],
      "metadata": {
        "id": "e057add5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viene qui definita la rete neurale di classificazione: è composta da due blocchi convoluzionali, uno per processare i dati a lungo termine (30 giorni prima) e una per quelli a breve termine (7 giorni prima). Nei blocchi convoluzionali viene eseguita una convoluzione, seguita da normalizzazione, funzione di attivazione Tanh e dropout, infine è posto un layer di pooling estrarre i dati più significativi.\n",
        "L'output dei due blocchi convoluzionali sono due vettori 1x768, che vengono concatenati col vettore 1x768 dei dati a breve termine (1 giorno prima) e il valore in apertura. Si ottiene dunque un vettore a 2323 dimensioni, che viene passato al layer in output per eseguire la classificazione binaria."
      ],
      "metadata": {
        "id": "neS82WVdTpD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        self.cnn_long = self.convolutional_block(c_in=1, c_out=8, dropout=0.3, kernel_size=(3, 1), stride=(3, 1))\n",
        "        self.maxpool_long = nn.MaxPool3d(kernel_size=(8, 10, 1))\n",
        "\n",
        "        self.cnn_mid = self.convolutional_block(c_in=1, c_out=8, dropout=0.3, kernel_size=(3, 1), stride=(3, 1), padding=(1, 0))\n",
        "        self.maxpool_mid = nn.MaxPool3d(kernel_size=(8, 3, 1))\n",
        "\n",
        "        self.out = nn.Linear(2323, 1) \n",
        "\n",
        "  def forward(self, data_long, data_mid, data_short, open_value):\n",
        "        x = self.cnn_long(data_long)\n",
        "        x = self.maxpool_long(x).squeeze(1)\n",
        "\n",
        "        y = self.cnn_mid(data_mid)\n",
        "        y = self.maxpool_mid(y).squeeze(1)\n",
        "        concat = torch.cat([x.squeeze(1), y.squeeze(1), data_short, open_value.unsqueeze(1)], dim=1) # concat of long, mid and short data into single vector of shace 1x2317\n",
        "\n",
        "        return self.out(concat)\n",
        "  \n",
        "  def convolutional_block(self, c_in, c_out, dropout, **kwargs):\n",
        "        block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=c_in, out_channels=c_out, **kwargs),\n",
        "            nn.BatchNorm2d(num_features=c_out),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(p=dropout)\n",
        "        )\n",
        "        return block"
      ],
      "metadata": {
        "id": "7e1b0462",
        "execution": {
          "iopub.status.busy": "2022-01-09T15:12:41.594441Z",
          "iopub.execute_input": "2022-01-09T15:12:41.594922Z",
          "iopub.status.idle": "2022-01-09T15:12:41.606720Z",
          "shell.execute_reply.started": "2022-01-09T15:12:41.594885Z",
          "shell.execute_reply": "2022-01-09T15:12:41.605936Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier().to(device)"
      ],
      "metadata": {
        "id": "9295bc21",
        "execution": {
          "iopub.status.busy": "2022-01-09T15:12:41.608066Z",
          "iopub.execute_input": "2022-01-09T15:12:41.608616Z",
          "iopub.status.idle": "2022-01-09T15:12:41.619483Z",
          "shell.execute_reply.started": "2022-01-09T15:12:41.608581Z",
          "shell.execute_reply": "2022-01-09T15:12:41.618721Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Addestramento e valutazione"
      ],
      "metadata": {
        "id": "b961f5a3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vengono definiti un ottimizzatore e una funzione d'errore. La funzione di errore utilizzata è _binary cross entropy_ in quanto si tratta di un problema di classificazione binaria. Viene utilizzata la versione _with logits_ in quanto gli output della rete neurale non passano per una funzione di attivazione."
      ],
      "metadata": {
        "id": "LdJ8xWwiTcnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 200\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "loss_fn = nn.BCEWithLogitsLoss().to(device)"
      ],
      "metadata": {
        "id": "489b21db",
        "execution": {
          "iopub.status.busy": "2022-01-09T15:12:41.621735Z",
          "iopub.execute_input": "2022-01-09T15:12:41.623157Z",
          "iopub.status.idle": "2022-01-09T15:12:41.629892Z",
          "shell.execute_reply.started": "2022-01-09T15:12:41.623113Z",
          "shell.execute_reply": "2022-01-09T15:12:41.629094Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Secondo le indicazioni della [documentazione PyTorch](https://pytorch.org/docs/stable/optim.html), vengono definiti gli step per l'addestramento e la valutazione del modello. "
      ],
      "metadata": {
        "id": "pUY3SQuGTl2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, data_loader, loss_fn, optimizer, scheduler, n_examples, device):\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  step = 0\n",
        "  for d in data_loader:\n",
        "      step += 1\n",
        "      optimizer.zero_grad() # clears previous gradients\n",
        "      data_long = d[\"data_long\"].unsqueeze(1).to(device)\n",
        "      data_mid = d[\"data_mid\"].unsqueeze(1).to(device)\n",
        "      data_short = d[\"data_short\"].to(device)\n",
        "      open_value = d[\"open_value\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "      outputs = model(data_long, data_mid, data_short, open_value)\n",
        "      preds = outputs>0    \n",
        "      loss = loss_fn(outputs, targets.unsqueeze(1)) # computes loss\n",
        "      correct_predictions += torch.sum(torch.transpose(preds, 0, 1) == targets)\n",
        "      losses.append(loss.item())\n",
        "      loss.backward() \n",
        "      nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "      optimizer.step() # optimizer takes step based on gradients\n",
        "      scheduler.step() \n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "3888edac",
        "execution": {
          "iopub.status.busy": "2022-01-09T15:12:41.631178Z",
          "iopub.execute_input": "2022-01-09T15:12:41.631768Z",
          "iopub.status.idle": "2022-01-09T15:12:41.641801Z",
          "shell.execute_reply.started": "2022-01-09T15:12:41.631733Z",
          "shell.execute_reply": "2022-01-09T15:12:41.641072Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  step = 0\n",
        "  with torch.no_grad(): # gradient computation disabled for evalutaion\n",
        "      for d in data_loader:\n",
        "        step += 1\n",
        "        data_long = d[\"data_long\"].unsqueeze(1).to(device)\n",
        "        data_mid = d[\"data_mid\"].unsqueeze(1).to(device)\n",
        "        data_short = d[\"data_short\"].to(device)\n",
        "        open_value = d[\"open_value\"].to(device)\n",
        "        targets = d[\"targets\"].to(device)\n",
        "        outputs = model(data_long, data_mid, data_short, open_value)\n",
        "        preds = (outputs>0)    \n",
        "        loss = loss_fn(outputs, targets.unsqueeze(1))\n",
        "        correct_predictions += torch.sum(torch.transpose(preds, 0, 1) == targets)\n",
        "        losses.append(loss.item())\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "b62800a8",
        "execution": {
          "iopub.status.busy": "2022-01-09T15:12:41.642900Z",
          "iopub.execute_input": "2022-01-09T15:12:41.643745Z",
          "iopub.status.idle": "2022-01-09T15:12:41.660631Z",
          "shell.execute_reply.started": "2022-01-09T15:12:41.643669Z",
          "shell.execute_reply": "2022-01-09T15:12:41.659798Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = defaultdict(list)\n",
        "best_acc = 0\n",
        "for epoch in range(EPOCHS):\n",
        "  \n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    len(df_train),\n",
        "    device\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "  \n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    test_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_test)\n",
        "  )\n",
        "\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "  if float(val_acc) > float(best_acc):\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_acc = val_acc"
      ],
      "metadata": {
        "id": "1afecd30",
        "execution": {
          "iopub.status.busy": "2022-01-09T15:12:41.661798Z",
          "iopub.execute_input": "2022-01-09T15:12:41.662397Z",
          "iopub.status.idle": "2022-01-09T15:12:51.136441Z",
          "shell.execute_reply.started": "2022-01-09T15:12:41.662357Z",
          "shell.execute_reply": "2022-01-09T15:12:51.135686Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad7c739-1272-4f59-e462-fe4fd3e9e759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "Train loss 0.8297453083490071 accuracy 0.5047372954349698\n",
            "Val   loss 0.6778186162312826 accuracy 0.5966850828729282\n",
            "Epoch 2/200\n",
            "Train loss 0.7148721406334325 accuracy 0.49526270456503013\n",
            "Val   loss 0.7486032247543335 accuracy 0.4033149171270718\n",
            "Epoch 3/200\n",
            "Train loss 0.7273983202482525 accuracy 0.5271317829457365\n",
            "Val   loss 0.8211050828297933 accuracy 0.4033149171270718\n",
            "Epoch 4/200\n",
            "Train loss 0.7296877032832095 accuracy 0.5064599483204134\n",
            "Val   loss 0.8862437208493551 accuracy 0.4033149171270718\n",
            "Epoch 5/200\n",
            "Train loss 0.8022500088340357 accuracy 0.49612403100775193\n",
            "Val   loss 0.6962501605351766 accuracy 0.43646408839779005\n",
            "Epoch 6/200\n",
            "Train loss 0.7421632001274511 accuracy 0.5090439276485789\n",
            "Val   loss 0.7257506648699442 accuracy 0.4033149171270718\n",
            "Epoch 7/200\n",
            "Train loss 0.7118759374869498 accuracy 0.524547803617571\n",
            "Val   loss 0.7468772729237875 accuracy 0.4033149171270718\n",
            "Epoch 8/200\n",
            "Train loss 0.7094230808709797 accuracy 0.5176571920757967\n",
            "Val   loss 0.7238587935765585 accuracy 0.4033149171270718\n",
            "Epoch 9/200\n",
            "Train loss 0.7235391328209325 accuracy 0.5185185185185185\n",
            "Val   loss 0.6800440748532613 accuracy 0.6022099447513812\n",
            "Epoch 10/200\n",
            "Train loss 0.7001649298165974 accuracy 0.5159345391903531\n",
            "Val   loss 0.7506294846534729 accuracy 0.4033149171270718\n",
            "Epoch 11/200\n",
            "Train loss 0.6956358363753871 accuracy 0.5133505598621878\n",
            "Val   loss 0.8330705364545187 accuracy 0.4033149171270718\n",
            "Epoch 12/200\n",
            "Train loss 0.792411954779374 accuracy 0.49870801033591733\n",
            "Val   loss 0.6742752194404602 accuracy 0.5966850828729282\n",
            "Epoch 13/200\n",
            "Train loss 0.752409345225284 accuracy 0.49440137812230833\n",
            "Val   loss 0.7037738760312399 accuracy 0.42541436464088395\n",
            "Epoch 14/200\n",
            "Train loss 0.6982997969577187 accuracy 0.533161068044789\n",
            "Val   loss 0.685398797194163 accuracy 0.585635359116022\n",
            "Epoch 15/200\n",
            "Train loss 0.6999169619459855 accuracy 0.5348837209302325\n",
            "Val   loss 0.7183064023653666 accuracy 0.4143646408839779\n",
            "Epoch 16/200\n",
            "Train loss 0.7027924249046728 accuracy 0.5271317829457365\n",
            "Val   loss 0.7296117941538492 accuracy 0.42541436464088395\n",
            "Epoch 17/200\n",
            "Train loss 0.7015147397392675 accuracy 0.5211024978466839\n",
            "Val   loss 0.7643067042032877 accuracy 0.4033149171270718\n",
            "Epoch 18/200\n",
            "Train loss 0.7016528625237314 accuracy 0.5073212747631353\n",
            "Val   loss 0.950097660223643 accuracy 0.4033149171270718\n",
            "Epoch 19/200\n",
            "Train loss 0.7856450802401492 accuracy 0.5012919896640827\n",
            "Val   loss 0.6820035974184672 accuracy 0.5966850828729282\n",
            "Epoch 20/200\n",
            "Train loss 0.7926516564268815 accuracy 0.5073212747631353\n",
            "Val   loss 0.7594564954439799 accuracy 0.4033149171270718\n",
            "Epoch 21/200\n",
            "Train loss 0.7017964281533894 accuracy 0.5150732127476314\n",
            "Val   loss 0.71732497215271 accuracy 0.4198895027624309\n",
            "Epoch 22/200\n",
            "Train loss 0.6898375373137625 accuracy 0.5564168819982773\n",
            "Val   loss 0.9088742931683859 accuracy 0.4033149171270718\n",
            "Epoch 23/200\n",
            "Train loss 0.7495292017334386 accuracy 0.4926787252368648\n",
            "Val   loss 0.6927892764409384 accuracy 0.5303867403314917\n",
            "Epoch 24/200\n",
            "Train loss 0.691036393767909 accuracy 0.5434969853574505\n",
            "Val   loss 0.7212883234024048 accuracy 0.4198895027624309\n",
            "Epoch 25/200\n",
            "Train loss 0.6868920420345507 accuracy 0.5590008613264428\n",
            "Val   loss 0.755166749159495 accuracy 0.4088397790055248\n",
            "Epoch 26/200\n",
            "Train loss 0.7081781500264218 accuracy 0.5185185185185185\n",
            "Val   loss 0.8119994401931763 accuracy 0.4033149171270718\n",
            "Epoch 27/200\n",
            "Train loss 0.7187943207590204 accuracy 0.5228251507321274\n",
            "Val   loss 0.689420739809672 accuracy 0.5524861878453038\n",
            "Epoch 28/200\n",
            "Train loss 0.7074362227791234 accuracy 0.5254091300602929\n",
            "Val   loss 0.673163890838623 accuracy 0.6022099447513812\n",
            "Epoch 29/200\n",
            "Train loss 0.6853407213562414 accuracy 0.5469422911283376\n",
            "Val   loss 0.7580687801043192 accuracy 0.4198895027624309\n",
            "Epoch 30/200\n",
            "Train loss 0.7029534484210768 accuracy 0.5452196382428941\n",
            "Val   loss 0.7933235168457031 accuracy 0.4033149171270718\n",
            "Epoch 31/200\n",
            "Train loss 0.7214340630330538 accuracy 0.5219638242894057\n",
            "Val   loss 0.677882730960846 accuracy 0.5580110497237569\n",
            "Epoch 32/200\n",
            "Train loss 0.6867611878796628 accuracy 0.5676141257536607\n",
            "Val   loss 0.8233009576797485 accuracy 0.4033149171270718\n",
            "Epoch 33/200\n",
            "Train loss 0.7309092753811887 accuracy 0.5030146425495263\n",
            "Val   loss 0.6742077469825745 accuracy 0.580110497237569\n",
            "Epoch 34/200\n",
            "Train loss 0.709703222701424 accuracy 0.5314384151593454\n",
            "Val   loss 0.834703266620636 accuracy 0.4033149171270718\n",
            "Epoch 35/200\n",
            "Train loss 0.7150282734318784 accuracy 0.49870801033591733\n",
            "Val   loss 0.6814564069112142 accuracy 0.6077348066298343\n",
            "Epoch 36/200\n",
            "Train loss 0.7078085792692084 accuracy 0.5090439276485789\n",
            "Val   loss 0.7594798803329468 accuracy 0.4198895027624309\n",
            "Epoch 37/200\n",
            "Train loss 0.6876539054669832 accuracy 0.5684754521963824\n",
            "Val   loss 0.7090545097986857 accuracy 0.43646408839779005\n",
            "Epoch 38/200\n",
            "Train loss 0.697912617733604 accuracy 0.5254091300602929\n",
            "Val   loss 0.7838884989420573 accuracy 0.430939226519337\n",
            "Epoch 39/200\n",
            "Train loss 0.6925727787770724 accuracy 0.5555555555555556\n",
            "Val   loss 0.7084904511769613 accuracy 0.4475138121546961\n",
            "Epoch 40/200\n",
            "Train loss 0.6805199259205869 accuracy 0.5762273901808785\n",
            "Val   loss 0.7444372177124023 accuracy 0.42541436464088395\n",
            "Epoch 41/200\n",
            "Train loss 0.7041365190556175 accuracy 0.5159345391903531\n",
            "Val   loss 0.7635809381802877 accuracy 0.4198895027624309\n",
            "Epoch 42/200\n",
            "Train loss 0.6840619538959704 accuracy 0.5719207579672696\n",
            "Val   loss 0.7560580770174662 accuracy 0.430939226519337\n",
            "Epoch 43/200\n",
            "Train loss 0.6847858617180272 accuracy 0.5633074935400517\n",
            "Val   loss 0.7578666607538859 accuracy 0.4198895027624309\n",
            "Epoch 44/200\n",
            "Train loss 0.7066573845712762 accuracy 0.5279931093884582\n",
            "Val   loss 0.7525707880655924 accuracy 0.4198895027624309\n",
            "Epoch 45/200\n",
            "Train loss 0.6923344135284424 accuracy 0.5676141257536607\n",
            "Val   loss 0.7198787132898966 accuracy 0.46408839779005523\n",
            "Epoch 46/200\n",
            "Train loss 0.7364958116882726 accuracy 0.5262704565030146\n",
            "Val   loss 0.6852928002675375 accuracy 0.56353591160221\n",
            "Epoch 47/200\n",
            "Train loss 0.8122842405971727 accuracy 0.4935400516795866\n",
            "Val   loss 0.6842835744222006 accuracy 0.56353591160221\n",
            "Epoch 48/200\n",
            "Train loss 0.8406838084522047 accuracy 0.5055986218776917\n",
            "Val   loss 0.9313762982686361 accuracy 0.4033149171270718\n",
            "Epoch 49/200\n",
            "Train loss 0.8217368941558035 accuracy 0.5150732127476314\n",
            "Val   loss 0.965999186038971 accuracy 0.4033149171270718\n",
            "Epoch 50/200\n",
            "Train loss 0.7569399225084406 accuracy 0.5012919896640827\n",
            "Val   loss 0.8951977491378784 accuracy 0.4198895027624309\n",
            "Epoch 51/200\n",
            "Train loss 0.7456343424947638 accuracy 0.508182601205857\n",
            "Val   loss 0.7927064696947733 accuracy 0.42541436464088395\n",
            "Epoch 52/200\n",
            "Train loss 0.7433818139527973 accuracy 0.5116279069767442\n",
            "Val   loss 0.8582255641619364 accuracy 0.430939226519337\n",
            "Epoch 53/200\n",
            "Train loss 0.7011514400181017 accuracy 0.5254091300602929\n",
            "Val   loss 0.7095055977503458 accuracy 0.3867403314917127\n",
            "Epoch 54/200\n",
            "Train loss 0.6811097672111109 accuracy 0.5314384151593454\n",
            "Val   loss 0.7451965610186259 accuracy 0.42541436464088395\n",
            "Epoch 55/200\n",
            "Train loss 0.6770103824766058 accuracy 0.5727820844099913\n",
            "Val   loss 0.7281926075617472 accuracy 0.4419889502762431\n",
            "Epoch 56/200\n",
            "Train loss 0.6793281435966492 accuracy 0.5615848406546081\n",
            "Val   loss 0.7574301958084106 accuracy 0.4198895027624309\n",
            "Epoch 57/200\n",
            "Train loss 0.679346972390225 accuracy 0.5805340223944875\n",
            "Val   loss 0.7149282892545065 accuracy 0.4475138121546961\n",
            "Epoch 58/200\n",
            "Train loss 0.6703900130171525 accuracy 0.5857019810508183\n",
            "Val   loss 0.8233177065849304 accuracy 0.43646408839779005\n",
            "Epoch 59/200\n",
            "Train loss 0.6939547908933539 accuracy 0.5366063738156761\n",
            "Val   loss 0.7616928219795227 accuracy 0.42541436464088395\n",
            "Epoch 60/200\n",
            "Train loss 0.7125949106718364 accuracy 0.524547803617571\n",
            "Val   loss 0.8213144540786743 accuracy 0.43646408839779005\n",
            "Epoch 61/200\n",
            "Train loss 0.6912324052107962 accuracy 0.540913006029285\n",
            "Val   loss 0.7355706890424093 accuracy 0.43646408839779005\n",
            "Epoch 62/200\n",
            "Train loss 0.6837988872277109 accuracy 0.5443583118001722\n",
            "Val   loss 0.7429973483085632 accuracy 0.430939226519337\n",
            "Epoch 63/200\n",
            "Train loss 0.6737390317414936 accuracy 0.5762273901808785\n",
            "Val   loss 0.710811992486318 accuracy 0.4419889502762431\n",
            "Epoch 64/200\n",
            "Train loss 0.6772025729480543 accuracy 0.5762273901808785\n",
            "Val   loss 0.7304069598515829 accuracy 0.4198895027624309\n",
            "Epoch 65/200\n",
            "Train loss 0.6733515858650208 accuracy 0.5788113695090439\n",
            "Val   loss 0.7315459648768107 accuracy 0.42541436464088395\n",
            "Epoch 66/200\n",
            "Train loss 0.6800150902647721 accuracy 0.5555555555555556\n",
            "Val   loss 0.7337515552838644 accuracy 0.42541436464088395\n",
            "Epoch 67/200\n",
            "Train loss 0.7096010572031924 accuracy 0.52885443583118\n",
            "Val   loss 0.8251422246297201 accuracy 0.42541436464088395\n",
            "Epoch 68/200\n",
            "Train loss 0.6880238683600175 accuracy 0.5391903531438416\n",
            "Val   loss 0.7726440827051798 accuracy 0.42541436464088395\n",
            "Epoch 69/200\n",
            "Train loss 0.6761979460716248 accuracy 0.5598621877691645\n",
            "Val   loss 0.7345785697301229 accuracy 0.42541436464088395\n",
            "Epoch 70/200\n",
            "Train loss 0.6712810836340252 accuracy 0.5633074935400517\n",
            "Val   loss 0.7191477417945862 accuracy 0.4475138121546961\n",
            "Epoch 71/200\n",
            "Train loss 0.6664585377040663 accuracy 0.5779500430663221\n",
            "Val   loss 0.7215938568115234 accuracy 0.4419889502762431\n",
            "Epoch 72/200\n",
            "Train loss 0.6727801718209919 accuracy 0.5641688199827735\n",
            "Val   loss 0.7079204320907593 accuracy 0.4475138121546961\n",
            "Epoch 73/200\n",
            "Train loss 0.6654161999100133 accuracy 0.6063738156761412\n",
            "Val   loss 0.745495080947876 accuracy 0.430939226519337\n",
            "Epoch 74/200\n",
            "Train loss 0.6701037821016813 accuracy 0.570198105081826\n",
            "Val   loss 0.766980508963267 accuracy 0.4419889502762431\n",
            "Epoch 75/200\n",
            "Train loss 0.6712246066645572 accuracy 0.5719207579672696\n",
            "Val   loss 0.7641875743865967 accuracy 0.43646408839779005\n",
            "Epoch 76/200\n",
            "Train loss 0.6688557141705563 accuracy 0.5719207579672696\n",
            "Val   loss 0.783826490243276 accuracy 0.43646408839779005\n",
            "Epoch 77/200\n",
            "Train loss 0.6690228518686796 accuracy 0.5831180017226529\n",
            "Val   loss 0.8111657897631327 accuracy 0.4088397790055248\n",
            "Epoch 78/200\n",
            "Train loss 0.685756620607878 accuracy 0.5745047372954349\n",
            "Val   loss 0.8192950089772543 accuracy 0.4033149171270718\n",
            "Epoch 79/200\n",
            "Train loss 0.698642373085022 accuracy 0.5633074935400517\n",
            "Val   loss 0.8452784816424052 accuracy 0.4033149171270718\n",
            "Epoch 80/200\n",
            "Train loss 0.7077262307468214 accuracy 0.5340223944875108\n",
            "Val   loss 0.7714294791221619 accuracy 0.430939226519337\n",
            "Epoch 81/200\n",
            "Train loss 0.6663270529947782 accuracy 0.5831180017226529\n",
            "Val   loss 0.745121161142985 accuracy 0.430939226519337\n",
            "Epoch 82/200\n",
            "Train loss 0.6620701896516901 accuracy 0.5917312661498708\n",
            "Val   loss 0.7690543333689371 accuracy 0.42541436464088395\n",
            "Epoch 83/200\n",
            "Train loss 0.6702630990429929 accuracy 0.5822566752799311\n",
            "Val   loss 0.8182464241981506 accuracy 0.4033149171270718\n",
            "Epoch 84/200\n",
            "Train loss 0.6721985465601871 accuracy 0.5822566752799311\n",
            "Val   loss 0.754565954208374 accuracy 0.42541436464088395\n",
            "Epoch 85/200\n",
            "Train loss 0.6672685679636503 accuracy 0.5796726959517657\n",
            "Val   loss 0.7585176626841227 accuracy 0.4419889502762431\n",
            "Epoch 86/200\n",
            "Train loss 0.667406019411589 accuracy 0.5900086132644272\n",
            "Val   loss 0.7706390817960104 accuracy 0.43646408839779005\n",
            "Epoch 87/200\n",
            "Train loss 0.6645866569719816 accuracy 0.58656330749354\n",
            "Val   loss 0.7543927232424418 accuracy 0.4419889502762431\n",
            "Epoch 88/200\n",
            "Train loss 0.6687502515943426 accuracy 0.5813953488372093\n",
            "Val   loss 0.7370943228403727 accuracy 0.430939226519337\n",
            "Epoch 89/200\n",
            "Train loss 0.6658965631535179 accuracy 0.5917312661498708\n",
            "Val   loss 0.7266035874684652 accuracy 0.4475138121546961\n",
            "Epoch 90/200\n",
            "Train loss 0.6615567458303351 accuracy 0.5900086132644272\n",
            "Val   loss 0.7457976341247559 accuracy 0.43646408839779005\n",
            "Epoch 91/200\n",
            "Train loss 0.6613467900376571 accuracy 0.5874246339362619\n",
            "Val   loss 0.7131458322207133 accuracy 0.4198895027624309\n",
            "Epoch 92/200\n",
            "Train loss 0.6688570850773862 accuracy 0.5891472868217055\n",
            "Val   loss 0.7214643756548563 accuracy 0.430939226519337\n",
            "Epoch 93/200\n",
            "Train loss 0.6578769809321353 accuracy 0.6072351421188631\n",
            "Val   loss 0.7270567019780477 accuracy 0.4198895027624309\n",
            "Epoch 94/200\n",
            "Train loss 0.6567951315327695 accuracy 0.6149870801033591\n",
            "Val   loss 0.7124470671017965 accuracy 0.43646408839779005\n",
            "Epoch 95/200\n",
            "Train loss 0.6592020925722624 accuracy 0.6046511627906976\n",
            "Val   loss 0.749629815419515 accuracy 0.42541436464088395\n",
            "Epoch 96/200\n",
            "Train loss 0.662756107355419 accuracy 0.6020671834625323\n",
            "Val   loss 0.7440163095792135 accuracy 0.4143646408839779\n",
            "Epoch 97/200\n",
            "Train loss 0.6579983014809457 accuracy 0.6098191214470284\n",
            "Val   loss 0.7383427222569784 accuracy 0.4143646408839779\n",
            "Epoch 98/200\n",
            "Train loss 0.6574307052712691 accuracy 0.6089577950043066\n",
            "Val   loss 0.7433318694432577 accuracy 0.42541436464088395\n",
            "Epoch 99/200\n",
            "Train loss 0.6579252105010184 accuracy 0.6089577950043066\n",
            "Val   loss 0.7570493618647257 accuracy 0.430939226519337\n",
            "Epoch 100/200\n",
            "Train loss 0.6600387159146761 accuracy 0.5934539190353144\n",
            "Val   loss 0.743213951587677 accuracy 0.42541436464088395\n",
            "Epoch 101/200\n",
            "Train loss 0.658162932646902 accuracy 0.6149870801033591\n",
            "Val   loss 0.7329784035682678 accuracy 0.4143646408839779\n",
            "Epoch 102/200\n",
            "Train loss 0.6530238515452335 accuracy 0.6236003445305771\n",
            "Val   loss 0.7302846312522888 accuracy 0.430939226519337\n",
            "Epoch 103/200\n",
            "Train loss 0.6549234860821774 accuracy 0.6210163652024118\n",
            "Val   loss 0.7235418756802877 accuracy 0.430939226519337\n",
            "Epoch 104/200\n",
            "Train loss 0.6526297581823248 accuracy 0.6175710594315246\n",
            "Val   loss 0.7309200366338094 accuracy 0.4198895027624309\n",
            "Epoch 105/200\n",
            "Train loss 0.6576072636403536 accuracy 0.6227390180878553\n",
            "Val   loss 0.7255341013272604 accuracy 0.43646408839779005\n",
            "Epoch 106/200\n",
            "Train loss 0.6561445342866998 accuracy 0.6149870801033591\n",
            "Val   loss 0.7207441926002502 accuracy 0.4475138121546961\n",
            "Epoch 107/200\n",
            "Train loss 0.6526713998694169 accuracy 0.6236003445305771\n",
            "Val   loss 0.7294666568438212 accuracy 0.43646408839779005\n",
            "Epoch 108/200\n",
            "Train loss 0.6533985671244169 accuracy 0.6055124892334195\n",
            "Val   loss 0.729361871878306 accuracy 0.42541436464088395\n",
            "Epoch 109/200\n",
            "Train loss 0.6570464749085275 accuracy 0.6175710594315246\n",
            "Val   loss 0.7241648038228353 accuracy 0.4419889502762431\n",
            "Epoch 110/200\n",
            "Train loss 0.656505961167185 accuracy 0.6175710594315246\n",
            "Val   loss 0.7148196895917257 accuracy 0.4530386740331491\n",
            "Epoch 111/200\n",
            "Train loss 0.6523567751834267 accuracy 0.6175710594315246\n",
            "Val   loss 0.7271762092908224 accuracy 0.42541436464088395\n",
            "Epoch 112/200\n",
            "Train loss 0.653154919022008 accuracy 0.6244616709732989\n",
            "Val   loss 0.7332170009613037 accuracy 0.4198895027624309\n",
            "Epoch 113/200\n",
            "Train loss 0.6528796647724352 accuracy 0.6080964685615848\n",
            "Val   loss 0.729649821917216 accuracy 0.430939226519337\n",
            "Epoch 114/200\n",
            "Train loss 0.6502261977446707 accuracy 0.6175710594315246\n",
            "Val   loss 0.7474788228670756 accuracy 0.42541436464088395\n",
            "Epoch 115/200\n",
            "Train loss 0.6566580784948248 accuracy 0.6055124892334195\n",
            "Val   loss 0.7460254430770874 accuracy 0.430939226519337\n",
            "Epoch 116/200\n",
            "Train loss 0.65361235643688 accuracy 0.611541774332472\n",
            "Val   loss 0.725182851155599 accuracy 0.43646408839779005\n",
            "Epoch 117/200\n",
            "Train loss 0.6511396828450655 accuracy 0.6287683031869078\n",
            "Val   loss 0.7332183917363485 accuracy 0.43646408839779005\n",
            "Epoch 118/200\n",
            "Train loss 0.6519712899860582 accuracy 0.6132644272179156\n",
            "Val   loss 0.7323712706565857 accuracy 0.4585635359116022\n",
            "Epoch 119/200\n",
            "Train loss 0.6537396186276486 accuracy 0.6201550387596899\n",
            "Val   loss 0.7329769730567932 accuracy 0.43646408839779005\n",
            "Epoch 120/200\n",
            "Train loss 0.6542496932180304 accuracy 0.6201550387596899\n",
            "Val   loss 0.7123987078666687 accuracy 0.46408839779005523\n",
            "Epoch 121/200\n",
            "Train loss 0.6488825239633259 accuracy 0.6253229974160207\n",
            "Val   loss 0.7041656970977783 accuracy 0.47513812154696133\n",
            "Epoch 122/200\n",
            "Train loss 0.6481150137750726 accuracy 0.6253229974160207\n",
            "Val   loss 0.7087796926498413 accuracy 0.46961325966850825\n",
            "Epoch 123/200\n",
            "Train loss 0.6516642727349934 accuracy 0.6132644272179156\n",
            "Val   loss 0.7123992443084717 accuracy 0.46961325966850825\n",
            "Epoch 124/200\n",
            "Train loss 0.6504684843515095 accuracy 0.6227390180878553\n",
            "Val   loss 0.726410984992981 accuracy 0.4475138121546961\n",
            "Epoch 125/200\n",
            "Train loss 0.6487660313907423 accuracy 0.6236003445305771\n",
            "Val   loss 0.7274828553199768 accuracy 0.4475138121546961\n",
            "Epoch 126/200\n",
            "Train loss 0.6485559532516881 accuracy 0.6270456503014643\n",
            "Val   loss 0.7405645449956259 accuracy 0.430939226519337\n",
            "Epoch 127/200\n",
            "Train loss 0.6477195871503729 accuracy 0.6304909560723514\n",
            "Val   loss 0.7303134997685751 accuracy 0.43646408839779005\n",
            "Epoch 128/200\n",
            "Train loss 0.6484909873259695 accuracy 0.6236003445305771\n",
            "Val   loss 0.7290727694829305 accuracy 0.43646408839779005\n",
            "Epoch 129/200\n",
            "Train loss 0.6457700823482714 accuracy 0.632213608957795\n",
            "Val   loss 0.7310499350229899 accuracy 0.43646408839779005\n",
            "Epoch 130/200\n",
            "Train loss 0.6472826568703902 accuracy 0.6408268733850129\n",
            "Val   loss 0.7250401973724365 accuracy 0.4419889502762431\n",
            "Epoch 131/200\n",
            "Train loss 0.648921505401009 accuracy 0.6296296296296297\n",
            "Val   loss 0.7354637781778971 accuracy 0.4475138121546961\n",
            "Epoch 132/200\n",
            "Train loss 0.6447743522493463 accuracy 0.6391042204995694\n",
            "Val   loss 0.7276739080746969 accuracy 0.43646408839779005\n",
            "Epoch 133/200\n",
            "Train loss 0.6448955316292612 accuracy 0.632213608957795\n",
            "Val   loss 0.7193062702814738 accuracy 0.4475138121546961\n",
            "Epoch 134/200\n",
            "Train loss 0.6472852951601932 accuracy 0.6330749354005168\n",
            "Val   loss 0.7264691988627116 accuracy 0.4530386740331491\n",
            "Epoch 135/200\n",
            "Train loss 0.6430524242551703 accuracy 0.632213608957795\n",
            "Val   loss 0.7319554885228475 accuracy 0.43646408839779005\n",
            "Epoch 136/200\n",
            "Train loss 0.6462354126729464 accuracy 0.6184323858742463\n",
            "Val   loss 0.723518451054891 accuracy 0.4585635359116022\n",
            "Epoch 137/200\n",
            "Train loss 0.6442281854780096 accuracy 0.6296296296296297\n",
            "Val   loss 0.7235645651817322 accuracy 0.4585635359116022\n",
            "Epoch 138/200\n",
            "Train loss 0.6419118140873156 accuracy 0.6347975882859603\n",
            "Val   loss 0.7205129464467367 accuracy 0.4419889502762431\n",
            "Epoch 139/200\n",
            "Train loss 0.643811263536152 accuracy 0.632213608957795\n",
            "Val   loss 0.7166306177775065 accuracy 0.4585635359116022\n",
            "Epoch 140/200\n",
            "Train loss 0.6465784060327631 accuracy 0.6356589147286822\n",
            "Val   loss 0.7165664235750834 accuracy 0.46961325966850825\n",
            "Epoch 141/200\n",
            "Train loss 0.6398572451189944 accuracy 0.6408268733850129\n",
            "Val   loss 0.7169958154360453 accuracy 0.4585635359116022\n",
            "Epoch 142/200\n",
            "Train loss 0.6455220768326208 accuracy 0.6356589147286822\n",
            "Val   loss 0.716934065024058 accuracy 0.4530386740331491\n",
            "Epoch 143/200\n",
            "Train loss 0.6443274962274652 accuracy 0.6270456503014643\n",
            "Val   loss 0.7318699359893799 accuracy 0.43646408839779005\n",
            "Epoch 144/200\n",
            "Train loss 0.6430585321627165 accuracy 0.6365202411714039\n",
            "Val   loss 0.7260966499646505 accuracy 0.4475138121546961\n",
            "Epoch 145/200\n",
            "Train loss 0.6476295809996756 accuracy 0.6330749354005168\n",
            "Val   loss 0.7307552099227905 accuracy 0.43646408839779005\n",
            "Epoch 146/200\n",
            "Train loss 0.6419698596000671 accuracy 0.6399655469422911\n",
            "Val   loss 0.7323002417882284 accuracy 0.4419889502762431\n",
            "Epoch 147/200\n",
            "Train loss 0.6424210604868437 accuracy 0.6347975882859603\n",
            "Val   loss 0.7205591797828674 accuracy 0.46408839779005523\n",
            "Epoch 148/200\n",
            "Train loss 0.6432128140800878 accuracy 0.6304909560723514\n",
            "Val   loss 0.7215189735094706 accuracy 0.4530386740331491\n",
            "Epoch 149/200\n",
            "Train loss 0.6440556739505968 accuracy 0.6210163652024118\n",
            "Val   loss 0.7300404906272888 accuracy 0.4530386740331491\n",
            "Epoch 150/200\n",
            "Train loss 0.6444394808066519 accuracy 0.6408268733850129\n",
            "Val   loss 0.7146850824356079 accuracy 0.46961325966850825\n",
            "Epoch 151/200\n",
            "Train loss 0.6479551948999104 accuracy 0.6287683031869078\n",
            "Val   loss 0.7189766764640808 accuracy 0.4530386740331491\n",
            "Epoch 152/200\n",
            "Train loss 0.6461076046291151 accuracy 0.6339362618432386\n",
            "Val   loss 0.7252521912256876 accuracy 0.4530386740331491\n",
            "Epoch 153/200\n",
            "Train loss 0.640184633041683 accuracy 0.6253229974160207\n",
            "Val   loss 0.7225203315416971 accuracy 0.4585635359116022\n",
            "Epoch 154/200\n",
            "Train loss 0.6450294977740237 accuracy 0.6365202411714039\n",
            "Val   loss 0.7148635387420654 accuracy 0.46961325966850825\n",
            "Epoch 155/200\n",
            "Train loss 0.6387775320755807 accuracy 0.6373815676141258\n",
            "Val   loss 0.7210593422253927 accuracy 0.4585635359116022\n",
            "Epoch 156/200\n",
            "Train loss 0.6422411736689115 accuracy 0.6304909560723514\n",
            "Val   loss 0.7340506116549174 accuracy 0.4419889502762431\n",
            "Epoch 157/200\n",
            "Train loss 0.6445345815859342 accuracy 0.6365202411714039\n",
            "Val   loss 0.7153863708178202 accuracy 0.47513812154696133\n",
            "Epoch 158/200\n",
            "Train loss 0.6361786095719588 accuracy 0.6347975882859603\n",
            "Val   loss 0.7331390976905823 accuracy 0.4475138121546961\n",
            "Epoch 159/200\n",
            "Train loss 0.6423592441960385 accuracy 0.6503014642549526\n",
            "Val   loss 0.7237838308016459 accuracy 0.4475138121546961\n",
            "Epoch 160/200\n",
            "Train loss 0.6380976658118399 accuracy 0.6296296296296297\n",
            "Val   loss 0.7210501631100973 accuracy 0.46408839779005523\n",
            "Epoch 161/200\n",
            "Train loss 0.6405017438687777 accuracy 0.6451335055986219\n",
            "Val   loss 0.7217724521954855 accuracy 0.46408839779005523\n",
            "Epoch 162/200\n",
            "Train loss 0.6361033916473389 accuracy 0.6425495262704565\n",
            "Val   loss 0.7154577374458313 accuracy 0.46961325966850825\n",
            "Epoch 163/200\n",
            "Train loss 0.6430953113656295 accuracy 0.6382428940568475\n",
            "Val   loss 0.7161673903465271 accuracy 0.46408839779005523\n",
            "Epoch 164/200\n",
            "Train loss 0.6429646924922341 accuracy 0.6244616709732989\n",
            "Val   loss 0.72496098279953 accuracy 0.4475138121546961\n",
            "Epoch 165/200\n",
            "Train loss 0.6379839872059069 accuracy 0.6459948320413437\n",
            "Val   loss 0.7190006772677103 accuracy 0.4585635359116022\n",
            "Epoch 166/200\n",
            "Train loss 0.6401217266132957 accuracy 0.6365202411714039\n",
            "Val   loss 0.7148963212966919 accuracy 0.47513812154696133\n",
            "Epoch 167/200\n",
            "Train loss 0.6381487846374512 accuracy 0.6451335055986219\n",
            "Val   loss 0.7244357069333395 accuracy 0.4475138121546961\n",
            "Epoch 168/200\n",
            "Train loss 0.6390423461010581 accuracy 0.6408268733850129\n",
            "Val   loss 0.7158233722050985 accuracy 0.46408839779005523\n",
            "Epoch 169/200\n",
            "Train loss 0.6406432139246088 accuracy 0.6459948320413437\n",
            "Val   loss 0.7285405596097311 accuracy 0.4530386740331491\n",
            "Epoch 170/200\n",
            "Train loss 0.6438906192779541 accuracy 0.6494401378122309\n",
            "Val   loss 0.7157110174496969 accuracy 0.46961325966850825\n",
            "Epoch 171/200\n",
            "Train loss 0.6422674122609591 accuracy 0.6451335055986219\n",
            "Val   loss 0.7291677991549174 accuracy 0.4419889502762431\n",
            "Epoch 172/200\n",
            "Train loss 0.6412707190764578 accuracy 0.6546080964685616\n",
            "Val   loss 0.7296069264411926 accuracy 0.4585635359116022\n",
            "Epoch 173/200\n",
            "Train loss 0.6432041274873834 accuracy 0.6391042204995694\n",
            "Val   loss 0.7162937124570211 accuracy 0.46408839779005523\n",
            "Epoch 174/200\n",
            "Train loss 0.6407596343442014 accuracy 0.632213608957795\n",
            "Val   loss 0.7272046407063802 accuracy 0.4475138121546961\n",
            "Epoch 175/200\n",
            "Train loss 0.6422680930087441 accuracy 0.6434108527131783\n",
            "Val   loss 0.7169809142748514 accuracy 0.46961325966850825\n",
            "Epoch 176/200\n",
            "Train loss 0.63886853268272 accuracy 0.6391042204995694\n",
            "Val   loss 0.7240504225095113 accuracy 0.4585635359116022\n",
            "Epoch 177/200\n",
            "Train loss 0.6370253311960321 accuracy 0.6459948320413437\n",
            "Val   loss 0.71824049949646 accuracy 0.46961325966850825\n",
            "Epoch 178/200\n",
            "Train loss 0.6426179722735756 accuracy 0.6451335055986219\n",
            "Val   loss 0.7195817033449808 accuracy 0.46408839779005523\n",
            "Epoch 179/200\n",
            "Train loss 0.6385301947593689 accuracy 0.6425495262704565\n",
            "Val   loss 0.716695229212443 accuracy 0.46961325966850825\n",
            "Epoch 180/200\n",
            "Train loss 0.6353847102115029 accuracy 0.6451335055986219\n",
            "Val   loss 0.7241072456041971 accuracy 0.46408839779005523\n",
            "Epoch 181/200\n",
            "Train loss 0.6386721855715701 accuracy 0.6468561584840654\n",
            "Val   loss 0.722446064154307 accuracy 0.46408839779005523\n",
            "Epoch 182/200\n",
            "Train loss 0.6379501913723192 accuracy 0.6554694229112834\n",
            "Val   loss 0.7231581012407938 accuracy 0.4585635359116022\n",
            "Epoch 183/200\n",
            "Train loss 0.6399768496814527 accuracy 0.6399655469422911\n",
            "Val   loss 0.7195310592651367 accuracy 0.46408839779005523\n",
            "Epoch 184/200\n",
            "Train loss 0.6411651216055217 accuracy 0.6296296296296297\n",
            "Val   loss 0.720906138420105 accuracy 0.46961325966850825\n",
            "Epoch 185/200\n",
            "Train loss 0.6366406428186517 accuracy 0.6356589147286822\n",
            "Val   loss 0.7220792373021444 accuracy 0.46408839779005523\n",
            "Epoch 186/200\n",
            "Train loss 0.6384273924325642 accuracy 0.6459948320413437\n",
            "Val   loss 0.7274175683657328 accuracy 0.4475138121546961\n",
            "Epoch 187/200\n",
            "Train loss 0.6398932494615254 accuracy 0.6477174849267873\n",
            "Val   loss 0.7247091134389242 accuracy 0.4530386740331491\n",
            "Epoch 188/200\n",
            "Train loss 0.6370366466672797 accuracy 0.6451335055986219\n",
            "Val   loss 0.7195693453152975 accuracy 0.4585635359116022\n",
            "Epoch 189/200\n",
            "Train loss 0.6402369141578674 accuracy 0.6365202411714039\n",
            "Val   loss 0.7202049891153971 accuracy 0.46408839779005523\n",
            "Epoch 190/200\n",
            "Train loss 0.6410269047084608 accuracy 0.6416881998277347\n",
            "Val   loss 0.7238471508026123 accuracy 0.4585635359116022\n",
            "Epoch 191/200\n",
            "Train loss 0.6393951334451374 accuracy 0.648578811369509\n",
            "Val   loss 0.7200221220652262 accuracy 0.4585635359116022\n",
            "Epoch 192/200\n",
            "Train loss 0.6381784457909433 accuracy 0.6451335055986219\n",
            "Val   loss 0.7189755837122599 accuracy 0.46408839779005523\n",
            "Epoch 193/200\n",
            "Train loss 0.6346134731644079 accuracy 0.6477174849267873\n",
            "Val   loss 0.7193637092908224 accuracy 0.46961325966850825\n",
            "Epoch 194/200\n",
            "Train loss 0.6375765863217806 accuracy 0.6391042204995694\n",
            "Val   loss 0.7201661666234335 accuracy 0.46408839779005523\n",
            "Epoch 195/200\n",
            "Train loss 0.6364692167231911 accuracy 0.6408268733850129\n",
            "Val   loss 0.7244383891423544 accuracy 0.4585635359116022\n",
            "Epoch 196/200\n",
            "Train loss 0.6394323173322176 accuracy 0.6391042204995694\n",
            "Val   loss 0.7243425647417704 accuracy 0.4585635359116022\n",
            "Epoch 197/200\n",
            "Train loss 0.6376512615304244 accuracy 0.6339362618432386\n",
            "Val   loss 0.7229411999384562 accuracy 0.46408839779005523\n",
            "Epoch 198/200\n",
            "Train loss 0.6370188876202232 accuracy 0.6339362618432386\n",
            "Val   loss 0.7216234604517618 accuracy 0.46408839779005523\n",
            "Epoch 199/200\n",
            "Train loss 0.6386048480084068 accuracy 0.6399655469422911\n",
            "Val   loss 0.7208638191223145 accuracy 0.4585635359116022\n",
            "Epoch 200/200\n",
            "Train loss 0.6408779840720328 accuracy 0.6408268733850129\n",
            "Val   loss 0.7210882504781088 accuracy 0.4585635359116022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conclusioni"
      ],
      "metadata": {
        "id": "8DtAY3_zJU93"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Valutazione delle performance"
      ],
      "metadata": {
        "id": "BpEy-ub3QiYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vengono caricati i pesi relativi all'epoca con i risultati migliori in fase di addestramento"
      ],
      "metadata": {
        "id": "6ZWfesA7M1on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WEIGHTS = 'best_model_state.bin'\n",
        "model.load_state_dict(torch.load(WEIGHTS))"
      ],
      "metadata": {
        "id": "tZiRQR_xM0zR",
        "execution": {
          "iopub.status.busy": "2022-01-09T15:12:51.137574Z",
          "iopub.execute_input": "2022-01-09T15:12:51.138229Z",
          "iopub.status.idle": "2022-01-09T15:12:51.148736Z",
          "shell.execute_reply.started": "2022-01-09T15:12:51.138189Z",
          "shell.execute_reply": "2022-01-09T15:12:51.147842Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d9af89-4713-4b3b-bb38-10645af03b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 366
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viene fatta una valutazione finale del modello con tali pesi, con anche una confusion matrix per meglio interpretare i risultati."
      ],
      "metadata": {
        "id": "fJ4AcAr-M8mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# computes confusion matrix matches\n",
        "def compute_matches(preds, targets):\n",
        "  TP = FP = FN = TN = 0\n",
        "  targets = targets>0\n",
        "  \n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  targets = targets.detach().cpu().numpy()\n",
        "    \n",
        "  for i in range(len(preds)):\n",
        "      if(preds[i] and targets[i]):\n",
        "          TP += 1\n",
        "      elif(preds[i] and not targets[i]):\n",
        "          FP += 1\n",
        "      elif(not preds[i] and targets[i]):\n",
        "          FN += 1\n",
        "      else:\n",
        "          TN += 1\n",
        "          \n",
        "  return TP, FP, FN, TN"
      ],
      "metadata": {
        "id": "wb8FO9UzyWH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final_model_evaluation(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  step = 0\n",
        "  dates = []\n",
        "  results = []\n",
        "  dictionary = {\n",
        "      \"TP\": 0,\n",
        "      \"FP\": 0,\n",
        "      \"FN\": 0,\n",
        "      \"TN\": 0\n",
        "  }\n",
        "  with torch.no_grad(): # gradient computation disabled for evalutaion\n",
        "      for d in data_loader:\n",
        "        step += 1\n",
        "        data_long = d[\"data_long\"].unsqueeze(1).to(device)\n",
        "        data_mid = d[\"data_mid\"].unsqueeze(1).to(device)\n",
        "        data_short = d[\"data_short\"].to(device)\n",
        "        open_value = d[\"open_value\"].to(device)\n",
        "        targets = d[\"targets\"].to(device)\n",
        "        outputs = model(data_long, data_mid, data_short, open_value)\n",
        "        preds = (outputs>0)\n",
        "        \n",
        "        matches = compute_matches(preds, targets)\n",
        "        dictionary[\"TP\"] += matches[0]\n",
        "        dictionary[\"FP\"] += matches[1]\n",
        "        dictionary[\"FN\"] += matches[2]\n",
        "        dictionary[\"TN\"] += matches[3]    \n",
        "\n",
        "        dates.append(d[\"date\"])\n",
        "        results.append((outputs>0).cpu().detach().numpy())\n",
        "        loss = loss_fn(outputs, targets.unsqueeze(1))\n",
        "        correct_predictions += torch.sum(torch.transpose(preds, 0, 1) == targets)\n",
        "        losses.append(loss.item())\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses), dictionary, results, dates"
      ],
      "metadata": {
        "id": "7219b9e7",
        "execution": {
          "iopub.status.busy": "2022-01-09T15:12:51.150324Z",
          "iopub.execute_input": "2022-01-09T15:12:51.150602Z",
          "iopub.status.idle": "2022-01-09T15:12:51.161420Z",
          "shell.execute_reply.started": "2022-01-09T15:12:51.150547Z",
          "shell.execute_reply": "2022-01-09T15:12:51.160522Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La **confusion matrix** sottostante mostra i valori predetti nelle righe e i valori reali nelle colonne, ed è da interpretarsi nel seguente modo:\n",
        "\n",
        "\n",
        "*   True positive, rialzo dell'indice predetto correttamente \n",
        "*   False positive, il modello ha predetto un rialzo dell'indice quando questo è invece diminuito\n",
        "*   False negative, il modello ha predetto una diminuzione dell'indice quando questo è invece aumentato\n",
        "*   True negative, ribasso dell'indice predetto correttamente\n",
        "\n"
      ],
      "metadata": {
        "id": "4GggDSkNI4Uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  val_acc, val_loss, dictionary, results, dates = final_model_evaluation(\n",
        "    model,\n",
        "    test_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_test)\n",
        "  ) \n",
        "  \n",
        "  print(f'Final model: loss {val_loss} accuracy {val_acc}')\n",
        "  pd.DataFrame([[\"True positives: \" + str(dictionary[\"TP\"]), \"False positives: \" + str(dictionary[\"FP\"])],\n",
        "              [\"False negatives: \" + str(dictionary[\"FN\"]), \"True negatives: \" + str(dictionary[\"TN\"])]],\n",
        "               index=[\"Predicted positive (1)\", \"Predicted negative (0)\"], columns=[\"Actually positive (1)\", \"Actually negative(0)\"])"
      ],
      "metadata": {
        "id": "25bacfec",
        "execution": {
          "iopub.status.busy": "2022-01-09T15:12:51.163068Z",
          "iopub.execute_input": "2022-01-09T15:12:51.163339Z",
          "iopub.status.idle": "2022-01-09T15:12:51.223801Z",
          "shell.execute_reply.started": "2022-01-09T15:12:51.163300Z",
          "shell.execute_reply": "2022-01-09T15:12:51.222657Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "137bf3b6-9b38-4ff0-ec21-5258ba017755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model: loss 0.6814564069112142 accuracy 0.6077348066298343\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c1a3189c-4e54-4948-b169-cbc682790480\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actually positive (1)</th>\n",
              "      <th>Actually negative(0)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Predicted positive (1)</th>\n",
              "      <td>True positives: 85</td>\n",
              "      <td>False positives: 48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Predicted negative (0)</th>\n",
              "      <td>False negatives: 23</td>\n",
              "      <td>True negatives: 25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1a3189c-4e54-4948-b169-cbc682790480')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1a3189c-4e54-4948-b169-cbc682790480 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1a3189c-4e54-4948-b169-cbc682790480');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                       Actually positive (1) Actually negative(0)\n",
              "Predicted positive (1)    True positives: 85  False positives: 48\n",
              "Predicted negative (0)   False negatives: 23   True negatives: 25"
            ]
          },
          "metadata": {},
          "execution_count": 369
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il paper originale utilizzava due metriche di performance : l'accuracy totale del modello e il coefficiente MCC, calcolato come: $$\\frac{T P ·T N −F P ·F N}{\\sqrt{(TP +FP)(TP +FN )(TN +FP)(TN +FN )}}$$\n",
        "(punteggio più alto è migliore). "
      ],
      "metadata": {
        "id": "kdU1nCL0NGip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mcc_num = dictionary[\"TP\"]*dictionary[\"TN\"]-dictionary[\"FP\"]*dictionary[\"FN\"]\n",
        "mcc_den = math.sqrt((dictionary[\"TP\"]+dictionary[\"FP\"])*(dictionary[\"TP\"]+dictionary[\"FN\"])*(dictionary[\"TN\"]+dictionary[\"FP\"])*(dictionary[\"TN\"]+dictionary[\"FN\"]))\n",
        "print(\"MCC:\", mcc_num/mcc_den)"
      ],
      "metadata": {
        "id": "OLy8Txo8rd79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c47f59e-4d5c-48af-a0c7-4878ec31c900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCC: 0.14391497782701282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calcolo del Return of investment"
      ],
      "metadata": {
        "id": "fATlnmNlY1GB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il modello sviluppato ha ottenuto le performance sperate, tuttavia per verificarne l'utilità pratica è importante simularne l'utilizzo in un contesto di compravendita di titoli di borsa. \n",
        "\n",
        "La simulazione avviene nel periodo coperto dai dati del test set: quando il modello prevede per una giornata un rialzo dell'indice S&P 500, acquista il titolo all'apertura dei mercati e lo rivende a fine giornata; viceversa se il modello prevede un ribasso dell'indice, lo vende allo scoperto (naked short selling) a inizio giornata e lo ricompra a fine giornata."
      ],
      "metadata": {
        "id": "Gud1MIWkdMGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame({'Date': [], 'Prediction': []}) # prediction for each day in test set\n",
        "results_df[\"Date\"] = np.concatenate(dates, axis = 0)\n",
        "results_df[\"Prediction\"] = np.concatenate(results, axis = 0)\n",
        "results_df['Date'] = results_df['Date'].astype(str).apply(lambda x: x.replace('-', ''))\n",
        "results_df['Date'] = results_df['Date'].apply(lambda x: datetime.date(int(x[:4]), int(x[4:6]), int(x[6:8]))) # datetime format to match dates\n",
        "results_df\n"
      ],
      "metadata": {
        "id": "GXL-1sakDW2l",
        "execution": {
          "iopub.status.busy": "2022-01-09T15:12:51.225176Z",
          "iopub.execute_input": "2022-01-09T15:12:51.225491Z",
          "iopub.status.idle": "2022-01-09T15:12:51.236469Z",
          "shell.execute_reply.started": "2022-01-09T15:12:51.225454Z",
          "shell.execute_reply": "2022-01-09T15:12:51.235803Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "a162c5b5-c305-42b6-af8f-3e5c73417671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-89def390-6c1f-4796-bbff-70481008f88e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-01-03</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-01-04</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-01-08</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-01-09</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-01-10</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>2013-11-20</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>2013-11-21</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>2013-11-22</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>2013-11-27</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>181 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89def390-6c1f-4796-bbff-70481008f88e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89def390-6c1f-4796-bbff-70481008f88e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89def390-6c1f-4796-bbff-70481008f88e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           Date  Prediction\n",
              "0    2013-01-03        True\n",
              "1    2013-01-04        True\n",
              "2    2013-01-08        True\n",
              "3    2013-01-09        True\n",
              "4    2013-01-10        True\n",
              "..          ...         ...\n",
              "176  2013-11-20       False\n",
              "177  2013-11-21       False\n",
              "178  2013-11-22       False\n",
              "179  2013-11-26       False\n",
              "180  2013-11-27       False\n",
              "\n",
              "[181 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 371
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viene calcolato il delta fra chiusura e apertura per quantificare i guadagni/perdite di ogni giorno di trading."
      ],
      "metadata": {
        "id": "uFQt0yCmMJEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stock_eval[\"Delta\"] = stock_eval['Close'] - stock_eval['Open'] # daily gain/loss\n",
        "gains_df = stock_eval[[\"Date\", \"Open\", \"Delta\"]]\n",
        "gains_df = gains_df.merge(results_df, on='Date')\n",
        "gains_df"
      ],
      "metadata": {
        "id": "yySHhfM0tj3y",
        "execution": {
          "iopub.status.busy": "2022-01-09T15:21:33.267250Z",
          "iopub.execute_input": "2022-01-09T15:21:33.267525Z",
          "iopub.status.idle": "2022-01-09T15:21:33.292967Z",
          "shell.execute_reply.started": "2022-01-09T15:21:33.267493Z",
          "shell.execute_reply": "2022-01-09T15:21:33.292093Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "efd159c8-56e8-405d-d4c1-95c453a01ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-980eeea1-e538-4ca2-ac2e-f5f315527497\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>Delta</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-01-03</td>\n",
              "      <td>1462.420044</td>\n",
              "      <td>-3.050049</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-01-04</td>\n",
              "      <td>1459.369995</td>\n",
              "      <td>7.099976</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-01-08</td>\n",
              "      <td>1461.890015</td>\n",
              "      <td>-4.739990</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-01-09</td>\n",
              "      <td>1457.150024</td>\n",
              "      <td>3.869995</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-01-10</td>\n",
              "      <td>1461.020020</td>\n",
              "      <td>11.099976</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>2013-11-20</td>\n",
              "      <td>1789.589966</td>\n",
              "      <td>-8.219971</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>2013-11-21</td>\n",
              "      <td>1783.520020</td>\n",
              "      <td>12.329956</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>2013-11-22</td>\n",
              "      <td>1797.209961</td>\n",
              "      <td>7.550049</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>1802.869995</td>\n",
              "      <td>-0.119995</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>2013-11-27</td>\n",
              "      <td>1803.479980</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>181 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-980eeea1-e538-4ca2-ac2e-f5f315527497')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-980eeea1-e538-4ca2-ac2e-f5f315527497 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-980eeea1-e538-4ca2-ac2e-f5f315527497');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           Date         Open      Delta  Prediction\n",
              "0    2013-01-03  1462.420044  -3.050049        True\n",
              "1    2013-01-04  1459.369995   7.099976        True\n",
              "2    2013-01-08  1461.890015  -4.739990        True\n",
              "3    2013-01-09  1457.150024   3.869995        True\n",
              "4    2013-01-10  1461.020020  11.099976        True\n",
              "..          ...          ...        ...         ...\n",
              "176  2013-11-20  1789.589966  -8.219971       False\n",
              "177  2013-11-21  1783.520020  12.329956       False\n",
              "178  2013-11-22  1797.209961   7.550049       False\n",
              "179  2013-11-26  1802.869995  -0.119995       False\n",
              "180  2013-11-27  1803.479980   3.750000       False\n",
              "\n",
              "[181 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GM server perché ha predetto il giorno successivo\n",
        "#gains_df['Prediction'] = gains_df.shift(periods=1)['Prediction']"
      ],
      "metadata": {
        "id": "QvqPoe0Hl2gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il guadagno _gain_ calcolato di seguito indica il guadagno assoluto in dollari realizzato dal modello nel periodo coperto dal test set: il modello opera ogni giorno acquistando o vendendo allo scoperto una unità del titolo S&P 500. Si noti che i guadagni assoluti realizzati dal modello aumenterebbero se venisse investito più denaro. Se si operasse per esempio ogni giorno con 10 unità del titolo, il guadagno sarebbe moltiplicato di 10 volte."
      ],
      "metadata": {
        "id": "FtAn1bfVeKVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gain = gains_df[gains_df[\"Prediction\"] == True][\"Delta\"].sum() - gains_df[gains_df[\"Prediction\"] == False][\"Delta\"].sum()\n",
        "gain"
      ],
      "metadata": {
        "id": "587YFVH0DcuN",
        "execution": {
          "iopub.status.busy": "2022-01-09T15:17:00.098917Z",
          "iopub.execute_input": "2022-01-09T15:17:00.099200Z",
          "iopub.status.idle": "2022-01-09T15:17:00.108455Z",
          "shell.execute_reply.started": "2022-01-09T15:17:00.099166Z",
          "shell.execute_reply": "2022-01-09T15:17:00.107699Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3bdf5c4-fce4-4867-e130-d34c90dc7e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300.70947265625"
            ]
          },
          "metadata": {},
          "execution_count": 374
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Poichè il guadagno dipende dalla quantità di denaro investito, una misura più indicativa della efficacia pratica del modello è il _ROI (return of investment)_. Il ROI non è altro che rapporto tra il guadagno e la cifra investita. In questo caso si considera la cifra investita come la media del valore di apertura di S&P 500 nel periodo preso in esame."
      ],
      "metadata": {
        "id": "IMSs07G1euN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "return_of_investment = gain/gains_df[\"Open\"].mean()\n",
        "return_of_investment"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-09T15:22:11.677527Z",
          "iopub.execute_input": "2022-01-09T15:22:11.678050Z",
          "iopub.status.idle": "2022-01-09T15:22:11.683655Z",
          "shell.execute_reply.started": "2022-01-09T15:22:11.678015Z",
          "shell.execute_reply": "2022-01-09T15:22:11.683004Z"
        },
        "trusted": true,
        "id": "q50fXISfc9H9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4985e7-9503-4d97-dfd7-57120c2864e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18478949873804618"
            ]
          },
          "metadata": {},
          "execution_count": 375
        }
      ]
    }
  ]
}